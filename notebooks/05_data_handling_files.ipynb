{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_data_handling_files\n",
    "File I/O, CSV, MAT, large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% Content to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File: notebooks/05_data_handling_files.ipynb\n",
    "\n",
    "# OctaveMasterPro: Data Handling & File I/O\n",
    "\n",
    "Master data import, export, and manipulation! This notebook covers file I/O operations, CSV handling, MAT files, and techniques for working with large datasets efficiently.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Master file input/output operations across formats\n",
    "- Handle CSV data import, export, and manipulation\n",
    "- Work with MAT files and binary data formats\n",
    "- Implement strategies for large dataset management\n",
    "- Apply data cleaning and preprocessing techniques\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Basic File I/O Operations\n",
    "\n",
    "```octave\n",
    "% Basic file input/output operations\n",
    "fprintf('=== Basic File I/O Operations ===\\n');\n",
    "\n",
    "% Text file writing\n",
    "filename_txt = 'sample_data.txt';\n",
    "fid = fopen(filename_txt, 'w');\n",
    "\n",
    "if fid == -1\n",
    "    error('Cannot open file for writing');\n",
    "end\n",
    "\n",
    "% Write various data types to text file\n",
    "fprintf(fid, 'Sample Data File\\n');\n",
    "fprintf(fid, 'Generated on: %s\\n', datestr(now()));\n",
    "fprintf(fid, '================\\n');\n",
    "fprintf(fid, 'Integer: %d\\n', 42);\n",
    "fprintf(fid, 'Float: %.4f\\n', pi);\n",
    "fprintf(fid, 'Scientific: %e\\n', 1.23e-6);\n",
    "\n",
    "% Write array data\n",
    "data_array = [1.1, 2.2, 3.3, 4.4, 5.5];\n",
    "fprintf(fid, 'Array: ');\n",
    "fprintf(fid, '%.2f ', data_array);\n",
    "fprintf(fid, '\\n');\n",
    "\n",
    "fclose(fid);\n",
    "fprintf('Text file written: %s\\n', filename_txt);\n",
    "\n",
    "% Text file reading\n",
    "fid = fopen(filename_txt, 'r');\n",
    "if fid == -1\n",
    "    error('Cannot open file for reading');\n",
    "end\n",
    "\n",
    "fprintf('Reading text file contents:\\n');\n",
    "line_count = 0;\n",
    "while ~feof(fid)\n",
    "    line = fgetl(fid);\n",
    "    if ischar(line)\n",
    "        line_count = line_count + 1;\n",
    "        fprintf('  Line %d: %s\\n', line_count, line);\n",
    "    end\n",
    "end\n",
    "\n",
    "fclose(fid);\n",
    "\n",
    "% Binary file operations\n",
    "binary_data = [1, 2, 3, 4, 5; 6, 7, 8, 9, 10];\n",
    "filename_bin = 'binary_data.bin';\n",
    "\n",
    "% Write binary data\n",
    "fid = fopen(filename_bin, 'wb');\n",
    "fwrite(fid, binary_data, 'double');\n",
    "fclose(fid);\n",
    "\n",
    "% Read binary data\n",
    "fid = fopen(filename_bin, 'rb');\n",
    "read_binary = fread(fid, [2, 5], 'double');\n",
    "fclose(fid);\n",
    "\n",
    "fprintf('Binary data round-trip test:\\n');\n",
    "fprintf('Original equal to read: %d\\n', isequal(binary_data, read_binary));\n",
    "\n",
    "% Clean up files\n",
    "delete(filename_txt);\n",
    "delete(filename_bin);\n",
    "```\n",
    "\n",
    "## 2. CSV File Operations\n",
    "\n",
    "```octave\n",
    "% CSV file handling and operations\n",
    "fprintf('\\n=== CSV File Operations ===\\n');\n",
    "\n",
    "% Create sample CSV data\n",
    "csv_filename = 'sample_data.csv';\n",
    "header_data = {'Name', 'Age', 'Score', 'Grade'};\n",
    "sample_data = {\n",
    "    'Alice', 25, 95.5, 'A';\n",
    "    'Bob', 23, 87.2, 'B';\n",
    "    'Charlie', 24, 92.8, 'A';\n",
    "    'Diana', 22, 78.5, 'C';\n",
    "    'Eve', 26, 88.9, 'B'\n",
    "};\n",
    "\n",
    "% Write CSV with headers (manual approach)\n",
    "fid = fopen(csv_filename, 'w');\n",
    "fprintf(fid, '%s,', header_data{1:end-1});\n",
    "fprintf(fid, '%s\\n', header_data{end});\n",
    "\n",
    "for i = 1:size(sample_data, 1)\n",
    "    fprintf(fid, '%s,%d,%.1f,%s\\n', sample_data{i,1}, sample_data{i,2}, ...\n",
    "            sample_data{i,3}, sample_data{i,4});\n",
    "end\n",
    "fclose(fid);\n",
    "\n",
    "fprintf('CSV file created: %s\\n', csv_filename);\n",
    "\n",
    "% Read CSV file (numeric data only for csvread)\n",
    "numeric_csv = 'numeric_data.csv';\n",
    "numeric_data = [10, 20, 30; 40, 50, 60; 70, 80, 90];\n",
    "csvwrite(numeric_csv, numeric_data);\n",
    "\n",
    "% Read numeric CSV\n",
    "read_numeric = csvread(numeric_csv);\n",
    "fprintf('Numeric CSV read successfully. Size: [%d, %d]\\n', ...\n",
    "        size(read_numeric, 1), size(read_numeric, 2));\n",
    "fprintf('Data verification: %d\\n', isequal(numeric_data, read_numeric));\n",
    "\n",
    "% Manual CSV parsing for mixed data\n",
    "function [headers, data] = parse_csv(filename)\n",
    "    % Parse CSV file with mixed data types\n",
    "    % Input: filename - CSV file path\n",
    "    % Output: headers - cell array of header names\n",
    "    %         data - cell array of data\n",
    "    \n",
    "    fid = fopen(filename, 'r');\n",
    "    if fid == -1\n",
    "        error('Cannot open CSV file: %s', filename);\n",
    "    end\n",
    "    \n",
    "    % Read header line\n",
    "    header_line = fgetl(fid);\n",
    "    headers = strsplit(header_line, ',');\n",
    "    \n",
    "    % Read data lines\n",
    "    data = {};\n",
    "    row = 1;\n",
    "    while ~feof(fid)\n",
    "        line = fgetl(fid);\n",
    "        if ischar(line) && ~isempty(line)\n",
    "            parts = strsplit(line, ',');\n",
    "            for col = 1:length(parts)\n",
    "                % Try to convert to number, otherwise keep as string\n",
    "                num_val = str2num(parts{col});\n",
    "                if ~isempty(num_val)\n",
    "                    data{row, col} = num_val;\n",
    "                else\n",
    "                    data{row, col} = parts{col};\n",
    "                end\n",
    "            end\n",
    "            row = row + 1;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    fclose(fid);\n",
    "end\n",
    "\n",
    "% Test CSV parsing\n",
    "[csv_headers, csv_data] = parse_csv(csv_filename);\n",
    "fprintf('CSV parsing results:\\n');\n",
    "fprintf('Headers: '); \n",
    "for i = 1:length(csv_headers)\n",
    "    fprintf('%s ', csv_headers{i});\n",
    "end\n",
    "fprintf('\\n');\n",
    "\n",
    "fprintf('Sample data rows:\\n');\n",
    "for i = 1:min(3, size(csv_data, 1))\n",
    "    fprintf('  Row %d: %s (age=%d, score=%.1f, grade=%s)\\n', i, ...\n",
    "            csv_data{i,1}, csv_data{i,2}, csv_data{i,3}, csv_data{i,4});\n",
    "end\n",
    "\n",
    "% Statistical analysis of CSV data\n",
    "ages = [csv_data{:,2}];\n",
    "scores = [csv_data{:,3}];\n",
    "\n",
    "fprintf('CSV data statistics:\\n');\n",
    "fprintf('  Age: mean=%.1f, std=%.1f\\n', mean(ages), std(ages));\n",
    "fprintf('  Score: mean=%.1f, std=%.1f\\n', mean(scores), std(scores));\n",
    "\n",
    "% Clean up\n",
    "delete(csv_filename);\n",
    "delete(numeric_csv);\n",
    "```\n",
    "\n",
    "## 3. MAT File Operations\n",
    "\n",
    "```octave\n",
    "% MAT file operations and data persistence\n",
    "fprintf('\\n=== MAT File Operations ===\\n');\n",
    "\n",
    "% Create diverse data for saving\n",
    "mat_filename = 'test_data.mat';\n",
    "\n",
    "% Various data types\n",
    "scalar_var = 42;\n",
    "vector_var = 1:10;\n",
    "matrix_var = magic(4);\n",
    "string_var = 'Hello MAT file';\n",
    "struct_var.name = 'John Doe';\n",
    "struct_var.age = 30;\n",
    "struct_var.scores = [85, 92, 78, 88];\n",
    "cell_var = {'apple', 123, [1,2,3], true};\n",
    "complex_var = 3 + 4i;\n",
    "\n",
    "% Save all variables to MAT file\n",
    "save(mat_filename, 'scalar_var', 'vector_var', 'matrix_var', ...\n",
    "     'string_var', 'struct_var', 'cell_var', 'complex_var');\n",
    "\n",
    "fprintf('MAT file saved: %s\\n', mat_filename);\n",
    "\n",
    "% Clear variables from workspace\n",
    "clear scalar_var vector_var matrix_var string_var struct_var cell_var complex_var;\n",
    "\n",
    "% Verify variables are cleared\n",
    "fprintf('Variables cleared from workspace\\n');\n",
    "\n",
    "% Load specific variables\n",
    "load(mat_filename, 'scalar_var', 'matrix_var');\n",
    "fprintf('Loaded specific variables:\\n');\n",
    "fprintf('  scalar_var = %d\\n', scalar_var);\n",
    "fprintf('  matrix_var size = [%d, %d]\\n', size(matrix_var, 1), size(matrix_var, 2));\n",
    "\n",
    "% Load all variables\n",
    "clear;  % Clear workspace\n",
    "load(mat_filename);\n",
    "fprintf('All variables reloaded:\\n');\n",
    "fprintf('  scalar_var = %d\\n', scalar_var);\n",
    "fprintf('  vector_var length = %d\\n', length(vector_var));\n",
    "fprintf('  string_var = %s\\n', string_var);\n",
    "fprintf('  struct_var.name = %s\\n', struct_var.name);\n",
    "fprintf('  complex_var = %.1f + %.1fi\\n', real(complex_var), imag(complex_var));\n",
    "\n",
    "% MAT file information without loading\n",
    "try\n",
    "    mat_info = whos('-file', mat_filename);\n",
    "    fprintf('MAT file contents:\\n');\n",
    "    for i = 1:length(mat_info)\n",
    "        fprintf('  %s: %s [%s]\\n', mat_info(i).name, mat_info(i).class, ...\n",
    "                num2str(mat_info(i).size));\n",
    "    end\n",
    "catch\n",
    "    fprintf('MAT file info not available in this environment\\n');\n",
    "end\n",
    "\n",
    "% Partial loading with conditions\n",
    "function loaded_data = conditional_load(filename, condition_func)\n",
    "    % Load MAT file data based on conditions\n",
    "    % Input: filename - MAT file path\n",
    "    %        condition_func - function to test variables\n",
    "    % Output: loaded_data - struct with loaded variables\n",
    "    \n",
    "    loaded_data = struct();\n",
    "    \n",
    "    try\n",
    "        file_vars = whos('-file', filename);\n",
    "        for i = 1:length(file_vars)\n",
    "            var_name = file_vars(i).name;\n",
    "            if condition_func(file_vars(i))\n",
    "                temp_data = load(filename, var_name);\n",
    "                loaded_data.(var_name) = temp_data.(var_name);\n",
    "            end\n",
    "        end\n",
    "    catch\n",
    "        % Fallback: load all and filter\n",
    "        all_data = load(filename);\n",
    "        field_names = fieldnames(all_data);\n",
    "        for i = 1:length(field_names)\n",
    "            var_name = field_names{i};\n",
    "            var_data = all_data.(var_name);\n",
    "            if condition_func(struct('name', var_name, 'class', class(var_data), 'size', size(var_data)))\n",
    "                loaded_data.(var_name) = var_data;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "% Test conditional loading\n",
    "numeric_condition = @(var_info) strcmp(var_info.class, 'double');\n",
    "numeric_vars = conditional_load(mat_filename, numeric_condition);\n",
    "fprintf('Loaded numeric variables: %s\\n', strjoin(fieldnames(numeric_vars), ', '));\n",
    "\n",
    "% Clean up\n",
    "delete(mat_filename);\n",
    "```\n",
    "\n",
    "## 4. Large Dataset Handling\n",
    "\n",
    "```octave\n",
    "% Strategies for handling large datasets\n",
    "fprintf('\\n=== Large Dataset Handling ===\\n');\n",
    "\n",
    "% Simulate large dataset creation\n",
    "large_filename = 'large_dataset.mat';\n",
    "fprintf('Creating simulated large dataset...\\n');\n",
    "\n",
    "% Create chunked data\n",
    "chunk_size = 1000;\n",
    "num_chunks = 5;\n",
    "total_rows = chunk_size * num_chunks;\n",
    "\n",
    "% Save data in chunks to simulate large file\n",
    "for chunk = 1:num_chunks\n",
    "    chunk_data = randn(chunk_size, 10);  % 1000x10 chunk\n",
    "    chunk_name = sprintf('data_chunk_%d', chunk);\n",
    "    \n",
    "    if chunk == 1\n",
    "        save(large_filename, chunk_name);\n",
    "    else\n",
    "        save(large_filename, chunk_name, '-append');\n",
    "    end\n",
    "end\n",
    "\n",
    "fprintf('Large dataset created: %d rows total in %d chunks\\n', total_rows, num_chunks);\n",
    "\n",
    "% Memory-efficient data processing\n",
    "function stats = process_large_dataset_chunked(filename, chunk_pattern)\n",
    "    % Process large dataset chunk by chunk\n",
    "    % Input: filename - MAT file path\n",
    "    %        chunk_pattern - pattern for chunk variable names\n",
    "    % Output: stats - aggregate statistics\n",
    "    \n",
    "    stats.total_elements = 0;\n",
    "    stats.sum = 0;\n",
    "    stats.sum_squares = 0;\n",
    "    stats.min_val = inf;\n",
    "    stats.max_val = -inf;\n",
    "    \n",
    "    chunk_num = 1;\n",
    "    while true\n",
    "        chunk_name = sprintf(chunk_pattern, chunk_num);\n",
    "        try\n",
    "            chunk_data = load(filename, chunk_name);\n",
    "            if isfield(chunk_data, chunk_name)\n",
    "                data = chunk_data.(chunk_name);\n",
    "                \n",
    "                % Update statistics incrementally\n",
    "                stats.total_elements = stats.total_elements + numel(data);\n",
    "                stats.sum = stats.sum + sum(data(:));\n",
    "                stats.sum_squares = stats.sum_squares + sum(data(:).^2);\n",
    "                stats.min_val = min(stats.min_val, min(data(:)));\n",
    "                stats.max_val = max(stats.max_val, max(data(:)));\n",
    "                \n",
    "                fprintf('  Processed chunk %d: %dx%d\\n', chunk_num, size(data,1), size(data,2));\n",
    "                chunk_num = chunk_num + 1;\n",
    "            else\n",
    "                break;\n",
    "            end\n",
    "        catch\n",
    "            break;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    % Calculate final statistics\n",
    "    stats.mean = stats.sum / stats.total_elements;\n",
    "    stats.variance = (stats.sum_squares - stats.total_elements * stats.mean^2) / (stats.total_elements - 1);\n",
    "    stats.std = sqrt(stats.variance);\n",
    "end\n",
    "\n",
    "% Process large dataset efficiently\n",
    "fprintf('Processing large dataset in chunks:\\n');\n",
    "large_stats = process_large_dataset_chunked(large_filename, 'data_chunk_%d');\n",
    "\n",
    "fprintf('Large dataset statistics:\\n');\n",
    "fprintf('  Total elements: %d\\n', large_stats.total_elements);\n",
    "fprintf('  Mean: %.6f\\n', large_stats.mean);\n",
    "fprintf('  Std: %.6f\\n', large_stats.std);\n",
    "fprintf('  Range: [%.6f, %.6f]\\n', large_stats.min_val, large_stats.max_val);\n",
    "\n",
    "% Memory usage monitoring (simplified)\n",
    "function monitor_memory_usage()\n",
    "    % Monitor memory usage during processing\n",
    "    try\n",
    "        % This would work in full Octave environment\n",
    "        mem_info = memory();\n",
    "        fprintf('Memory monitoring not available in this environment\\n');\n",
    "    catch\n",
    "        fprintf('Memory monitoring: Use ''memory'' command in full Octave\\n');\n",
    "    end\n",
    "end\n",
    "\n",
    "monitor_memory_usage();\n",
    "\n",
    "% Clean up\n",
    "delete(large_filename);\n",
    "```\n",
    "\n",
    "## 5. Data Import from Various Sources\n",
    "\n",
    "```octave\n",
    "% Data import from various file formats\n",
    "fprintf('\\n=== Data Import from Various Sources ===\\n');\n",
    "\n",
    "% Tab-separated values (TSV)\n",
    "tsv_filename = 'data.tsv';\n",
    "tsv_data = [1, 2, 3; 4, 5, 6; 7, 8, 9];\n",
    "\n",
    "% Write TSV file\n",
    "fid = fopen(tsv_filename, 'w');\n",
    "for i = 1:size(tsv_data, 1)\n",
    "    fprintf(fid, '%d', tsv_data(i, 1));\n",
    "    for j = 2:size(tsv_data, 2)\n",
    "        fprintf(fid, '\\t%d', tsv_data(i, j));\n",
    "    end\n",
    "    fprintf(fid, '\\n');\n",
    "end\n",
    "fclose(fid);\n",
    "\n",
    "% Read TSV file\n",
    "function data = read_tsv(filename)\n",
    "    % Read tab-separated values file\n",
    "    % Input: filename - TSV file path\n",
    "    % Output: data - numeric array\n",
    "    \n",
    "    fid = fopen(filename, 'r');\n",
    "    if fid == -1\n",
    "        error('Cannot open TSV file: %s', filename);\n",
    "    end\n",
    "    \n",
    "    data = [];\n",
    "    row = 1;\n",
    "    while ~feof(fid)\n",
    "        line = fgetl(fid);\n",
    "        if ischar(line) && ~isempty(line)\n",
    "            values = str2num(strrep(line, sprintf('\\t'), ' '));\n",
    "            data(row, :) = values;\n",
    "            row = row + 1;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    fclose(fid);\n",
    "end\n",
    "\n",
    "tsv_read = read_tsv(tsv_filename);\n",
    "fprintf('TSV read test: %d\\n', isequal(tsv_data, tsv_read));\n",
    "\n",
    "% Fixed-width format\n",
    "fixed_width_file = 'fixed_width.txt';\n",
    "fid = fopen(fixed_width_file, 'w');\n",
    "names = {'Alice', 'Bob  ', 'Charlie'};\n",
    "ages = [25, 30, 22];\n",
    "scores = [95.5, 87.2, 92.8];\n",
    "\n",
    "for i = 1:length(names)\n",
    "    fprintf(fid, '%-10s%3d%8.2f\\n', names{i}, ages(i), scores(i));\n",
    "end\n",
    "fclose(fid);\n",
    "\n",
    "% Read fixed-width file\n",
    "function [names, ages, scores] = read_fixed_width(filename)\n",
    "    % Read fixed-width format file\n",
    "    % Input: filename - file path\n",
    "    % Output: names, ages, scores - extracted data\n",
    "    \n",
    "    fid = fopen(filename, 'r');\n",
    "    if fid == -1\n",
    "        error('Cannot open fixed-width file: %s', filename);\n",
    "    end\n",
    "    \n",
    "    names = {};\n",
    "    ages = [];\n",
    "    scores = [];\n",
    "    \n",
    "    row = 1;\n",
    "    while ~feof(fid)\n",
    "        line = fgetl(fid);\n",
    "        if ischar(line) && length(line) >= 21\n",
    "            names{row} = strtrim(line(1:10));\n",
    "            ages(row) = str2num(line(11:13));\n",
    "            scores(row) = str2num(line(14:21));\n",
    "            row = row + 1;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    fclose(fid);\n",
    "end\n",
    "\n",
    "[fw_names, fw_ages, fw_scores] = read_fixed_width(fixed_width_file);\n",
    "fprintf('Fixed-width parsing results:\\n');\n",
    "for i = 1:length(fw_names)\n",
    "    fprintf('  %s: age=%d, score=%.1f\\n', fw_names{i}, fw_ages(i), fw_scores(i));\n",
    "end\n",
    "\n",
    "% JSON-like data handling (simplified)\n",
    "function data = parse_simple_json_like(text)\n",
    "    % Parse simple JSON-like text structure\n",
    "    % Input: text - JSON-like string\n",
    "    % Output: data - parsed structure\n",
    "    \n",
    "    % Remove whitespace and brackets\n",
    "    text = strrep(text, ' ', '');\n",
    "    text = strrep(text, '{', '');\n",
    "    text = strrep(text, '}', '');\n",
    "    \n",
    "    % Split by commas\n",
    "    pairs = strsplit(text, ',');\n",
    "    data = struct();\n",
    "    \n",
    "    for i = 1:length(pairs)\n",
    "        if contains(pairs{i}, ':')\n",
    "            key_val = strsplit(pairs{i}, ':');\n",
    "            key = strrep(key_val{1}, '\"', '');\n",
    "            val_str = strrep(key_val{2}, '\"', '');\n",
    "            \n",
    "            % Try to convert to number\n",
    "            val_num = str2num(val_str);\n",
    "            if ~isempty(val_num)\n",
    "                data.(key) = val_num;\n",
    "            else\n",
    "                data.(key) = val_str;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "json_text = '{\"name\":\"John\",\"age\":30,\"score\":85.5}';\n",
    "json_data = parse_simple_json_like(json_text);\n",
    "fprintf('JSON-like parsing: name=%s, age=%d, score=%.1f\\n', ...\n",
    "        json_data.name, json_data.age, json_data.score);\n",
    "\n",
    "% Clean up\n",
    "delete(tsv_filename);\n",
    "delete(fixed_width_file);\n",
    "```\n",
    "\n",
    "## 6. Data Validation and Cleaning\n",
    "\n",
    "```octave\n",
    "% Data validation and cleaning techniques\n",
    "fprintf('\\n=== Data Validation and Cleaning ===\\n');\n",
    "\n",
    "% Create messy dataset\n",
    "messy_data = [\n",
    "    1.5, 2.3, 3.1, 4.2, 5.5;\n",
    "    2.1, NaN, 3.8, 4.1, 5.2;\n",
    "    1.9, 2.7, -999, 4.5, 5.8;  % -999 as missing value indicator\n",
    "    2.3, 2.9, 3.4, Inf, 5.1;   % Infinite value\n",
    "    1.7, 2.1, 3.6, 4.8, 5.3;\n",
    "    2.0, 2.5, 3.2, 4.3, -999   % Another missing value\n",
    "];\n",
    "\n",
    "fprintf('Original messy data (%dx%d):\\n', size(messy_data, 1), size(messy_data, 2));\n",
    "fprintf('  NaN values: %d\\n', sum(isnan(messy_data(:))));\n",
    "fprintf('  Infinite values: %d\\n', sum(isinf(messy_data(:))));\n",
    "fprintf('  Missing indicators (-999): %d\\n', sum(messy_data(:) == -999));\n",
    "\n",
    "% Data cleaning function\n",
    "function [cleaned_data, cleaning_report] = clean_dataset(data, missing_value)\n",
    "    % Clean dataset by handling missing and invalid values\n",
    "    % Input: data - input dataset\n",
    "    %        missing_value - value indicating missing data\n",
    "    % Output: cleaned_data - cleaned dataset\n",
    "    %         cleaning_report - report of cleaning actions\n",
    "    \n",
    "    cleaning_report = struct();\n",
    "    cleaning_report.original_size = size(data);\n",
    "    \n",
    "    % Replace missing value indicators with NaN\n",
    "    data(data == missing_value) = NaN;\n",
    "    cleaning_report.missing_replaced = sum(data(:) == missing_value);\n",
    "    \n",
    "    % Handle infinite values\n",
    "    inf_mask = isinf(data);\n",
    "    cleaning_report.inf_values = sum(inf_mask(:));\n",
    "    data(inf_mask) = NaN;\n",
    "    \n",
    "    % Count total missing values\n",
    "    nan_mask = isnan(data);\n",
    "    cleaning_report.total_missing = sum(nan_mask(:));\n",
    "    \n",
    "    % Strategy 1: Remove rows with any missing values\n",
    "    complete_rows = ~any(nan_mask, 2);\n",
    "    cleaned_data_complete = data(complete_rows, :);\n",
    "    cleaning_report.rows_removed = sum(~complete_rows);\n",
    "    \n",
    "    % Strategy 2: Column-wise mean imputation\n",
    "    cleaned_data_imputed = data;\n",
    "    for col = 1:size(data, 2)\n",
    "        col_data = data(:, col);\n",
    "        valid_data = col_data(~isnan(col_data));\n",
    "        if ~isempty(valid_data)\n",
    "            col_mean = mean(valid_data);\n",
    "            cleaned_data_imputed(isnan(col_data), col) = col_mean;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    % Choose strategy based on data loss\n",
    "    complete_data_loss = (size(data, 1) - size(cleaned_data_complete, 1)) / size(data, 1);\n",
    "    \n",
    "    if complete_data_loss < 0.3  % Less than 30% data loss\n",
    "        cleaned_data = cleaned_data_complete;\n",
    "        cleaning_report.strategy = 'complete_case_removal';\n",
    "    else\n",
    "        cleaned_data = cleaned_data_imputed;\n",
    "        cleaning_report.strategy = 'mean_imputation';\n",
    "    end\n",
    "    \n",
    "    cleaning_report.final_size = size(cleaned_data);\n",
    "    cleaning_report.data_loss_percent = complete_data_loss * 100;\n",
    "end\n",
    "\n",
    "% Clean the messy dataset\n",
    "[clean_data, report] = clean_dataset(messy_data, -999);\n",
    "\n",
    "fprintf('Data cleaning results:\\n');\n",
    "fprintf('  Strategy used: %s\\n', report.strategy);\n",
    "fprintf('  Original size: [%d, %d]\\n', report.original_size);\n",
    "fprintf('  Final size: [%d, %d]\\n', report.final_size);\n",
    "fprintf('  Total missing values found: %d\\n', report.total_missing);\n",
    "fprintf('  Data loss: %.1f%%\\n', report.data_loss_percent);\n",
    "\n",
    "% Data validation functions\n",
    "function validation_report = validate_data(data, rules)\n",
    "    % Validate data against specified rules\n",
    "    % Input: data - dataset to validate\n",
    "    %        rules - struct with validation rules\n",
    "    % Output: validation_report - validation results\n",
    "    \n",
    "    validation_report = struct();\n",
    "    validation_report.passed = true;\n",
    "    validation_report.issues = {};\n",
    "    \n",
    "    % Check for missing values\n",
    "    if isfield(rules, 'allow_missing') && ~rules.allow_missing\n",
    "        missing_count = sum(isnan(data(:)));\n",
    "        if missing_count > 0\n",
    "            validation_report.passed = false;\n",
    "            validation_report.issues{end+1} = sprintf('Found %d missing values', missing_count);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    % Check data range\n",
    "    if isfield(rules, 'min_value')\n",
    "        below_min = sum(data(:) < rules.min_value);\n",
    "        if below_min > 0\n",
    "            validation_report.passed = false;\n",
    "            validation_report.issues{end+1} = sprintf('%d values below minimum %.2f', below_min, rules.min_value);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if isfield(rules, 'max_value')\n",
    "        above_max = sum(data(:) > rules.max_value);\n",
    "        if above_max > 0\n",
    "            validation_report.passed = false;\n",
    "            validation_report.issues{end+1} = sprintf('%d values above maximum %.2f', above_max, rules.max_value);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    % Check for outliers (using IQR method)\n",
    "    if isfield(rules, 'check_outliers') && rules.check_outliers\n",
    "        q1 = quantile(data(:), 0.25);\n",
    "        q3 = quantile(data(:), 0.75);\n",
    "        iqr = q3 - q1;\n",
    "        outlier_bounds = [q1 - 1.5*iqr, q3 + 1.5*iqr];\n",
    "        outliers = sum((data(:) < outlier_bounds(1)) | (data(:) > outlier_bounds(2)));\n",
    "        \n",
    "        validation_report.outliers = outliers;\n",
    "        if outliers > 0\n",
    "            validation_report.issues{end+1} = sprintf('Found %d potential outliers', outliers);\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "% Test data validation\n",
    "validation_rules.allow_missing = false;\n",
    "validation_rules.min_value = 0;\n",
    "validation_rules.max_value = 10;\n",
    "validation_rules.check_outliers = true;\n",
    "\n",
    "dirty_validation = validate_data(messy_data, validation_rules);\n",
    "clean_validation = validate_data(clean_data, validation_rules);\n",
    "\n",
    "fprintf('Validation results:\\n');\n",
    "fprintf('  Messy data passed: %d\\n', dirty_validation.passed);\n",
    "fprintf('  Clean data passed: %d\\n', clean_validation.passed);\n",
    "\n",
    "if ~clean_validation.passed\n",
    "    fprintf('  Remaining issues with clean data:\\n');\n",
    "    for i = 1:length(clean_validation.issues)\n",
    "        fprintf('    - %s\\n', clean_validation.issues{i});\n",
    "    end\n",
    "end\n",
    "```\n",
    "\n",
    "## 7. Data Export and Formatting\n",
    "\n",
    "```octave\n",
    "% Data export and formatting techniques\n",
    "fprintf('\\n=== Data Export and Formatting ===\\n');\n",
    "\n",
    "% Sample dataset for export\n",
    "export_data = struct();\n",
    "export_data.names = {'Alice', 'Bob', 'Charlie', 'Diana'};\n",
    "export_data.ages = [25, 30, 22, 28];\n",
    "export_data.scores = [95.5, 87.2, 92.8, 89.1];\n",
    "export_data.grades = {'A', 'B', 'A', 'B'};\n",
    "\n",
    "% Export to formatted text file\n",
    "formatted_file = 'formatted_report.txt';\n",
    "fid = fopen(formatted_file, 'w');\n",
    "\n",
    "fprintf(fid, 'STUDENT PERFORMANCE REPORT\\n');\n",
    "fprintf(fid, '==========================\\n');\n",
    "fprintf(fid, 'Generated: %s\\n\\n', datestr(now()));\n",
    "\n",
    "fprintf(fid, '%-12s %5s %8s %6s\\n', 'Name', 'Age', 'Score', 'Grade');\n",
    "fprintf(fid, '%s\\n', repmat('-', 1, 35));\n",
    "\n",
    "for i = 1:length(export_data.names)\n",
    "    fprintf(fid, '%-12s %5d %8.1f %6s\\n', export_data.names{i}, ...\n",
    "            export_data.ages(i), export_data.scores(i), export_data.grades{i});\n",
    "end\n",
    "\n",
    "fprintf(fid, '\\nSUMMARY STATISTICS:\\n');\n",
    "fprintf(fid, 'Average Age: %.1f years\\n', mean(export_data.ages));\n",
    "fprintf(fid, 'Average Score: %.1f points\\n', mean(export_data.scores));\n",
    "fprintf(fid, 'Total Students: %d\\n', length(export_data.names));\n",
    "\n",
    "fclose(fid);\n",
    "fprintf('Formatted report exported to: %s\\n', formatted_file);\n",
    "\n",
    "% Export to CSV with custom formatting\n",
    "custom_csv = 'custom_export.csv';\n",
    "fid = fopen(custom_csv, 'w');\n",
    "\n",
    "% Write header with metadata\n",
    "fprintf(fid, '# Student Performance Data\\n');\n",
    "fprintf(fid, '# Generated: %s\\n', datestr(now()));\n",
    "fprintf(fid, '# Total Records: %d\\n', length(export_data.names));\n",
    "fprintf(fid, 'Name,Age,Score,Grade,Performance\\n');\n",
    "\n",
    "for i = 1:length(export_data.names)\n",
    "    % Add calculated performance category\n",
    "    if export_data.scores(i) >= 90\n",
    "        performance = 'Excellent';\n",
    "    elseif export_data.scores(i) >= 80\n",
    "        performance = 'Good';\n",
    "    else\n",
    "        performance = 'Satisfactory';\n",
    "    end\n",
    "    \n",
    "    fprintf(fid, '%s,%d,%.1f,%s,%s\\n', export_data.names{i}, ...\n",
    "            export_data.ages(i), export_data.scores(i), ...\n",
    "            export_data.grades{i}, performance);\n",
    "end\n",
    "\n",
    "fclose(fid);\n",
    "fprintf('Custom CSV exported to: %s\\n', custom_csv);\n",
    "\n",
    "% Export configuration function\n",
    "function export_success = export_data_flexible(data, filename, format, options)\n",
    "    % Flexible data export function\n",
    "    % Input: data - struct with data fields\n",
    "    %        filename - output filename\n",
    "    %        format - 'csv', 'txt', 'mat'\n",
    "    %        options - export options struct\n",
    "    % Output: export_success - boolean success flag\n",
    "    \n",
    "    export_success = false;\n",
    "    \n",
    "    try\n",
    "        switch lower(format)\n",
    "            case 'csv'\n",
    "                export_csv_format(data, filename, options);\n",
    "            case 'txt'\n",
    "                export_text_format(data, filename, options);\n",
    "            case 'mat'\n",
    "                save(filename, '-struct', 'data');\n",
    "            otherwise\n",
    "                error('Unsupported format: %s', format);\n",
    "        end\n",
    "        export_success = true;\n",
    "    catch me\n",
    "        fprintf('Export failed: %s\\n', me.message);\n",
    "    end\n",
    "end\n",
    "\n",
    "function export_csv_format(data, filename, options)\n",
    "    % Export to CSV format\n",
    "    fid = fopen(filename, 'w');\n",
    "    \n",
    "    if isfield(options, 'include_header') && options.include_header\n",
    "        fields = fieldnames(data);\n",
    "        fprintf(fid, '%s', fields{1});\n",
    "        for i = 2:length(fields)\n",
    "            fprintf(fid, ',%s', fields{i});\n",
    "        end\n",
    "        fprintf(fid, '\\n');\n",
    "    end\n",
    "    \n",
    "    % Assume first field determines number of records\n",
    "    fields = fieldnames(data);\n",
    "    n_records = length(data.(fields{1}));\n",
    "    \n",
    "    for row = 1:n_records\n",
    "        fprintf(fid, '%s', num2str(data.(fields{1})(row)));\n",
    "        for col = 2:length(fields)\n",
    "            val = data.(fields{col})(row);\n",
    "            if isnumeric(val)\n",
    "                fprintf(fid, ',%.2f', val);\n",
    "            else\n",
    "                fprintf(fid, ',%s', val);\n",
    "            end\n",
    "        end\n",
    "        fprintf(fid, '\\n');\n",
    "    end\n",
    "    \n",
    "    fclose(fid);\n",
    "end\n",
    "\n",
    "function export_text_format(data, filename, options)\n",
    "    % Export to formatted text\n",
    "    fid = fopen(filename, 'w');\n",
    "    \n",
    "    if isfield(options, 'title')\n",
    "        fprintf(fid, '%s\\n', options.title);\n",
    "        fprintf(fid, '%s\\n', repmat('=', 1, length(options.title)));\n",
    "    end\n",
    "    \n",
    "    fields = fieldnames(data);\n",
    "    n_records = length(data.(fields{1}));\n",
    "    \n",
    "    for row = 1:n_records\n",
    "        for col = 1:length(fields)\n",
    "            val = data.(fields{col})(row);\n",
    "            if isnumeric(val)\n",
    "                fprintf(fid, '%s: %.2f  ', fields{col}, val);\n",
    "            else\n",
    "                fprintf(fid, '%s: %s  ', fields{col}, val);\n",
    "            end\n",
    "        end\n",
    "        fprintf(fid, '\\n');\n",
    "    end\n",
    "    \n",
    "    fclose(fid);\n",
    "end\n",
    "\n",
    "% Test flexible export\n",
    "export_options.include_header = true;\n",
    "export_options.title = 'Student Data Export';\n",
    "\n",
    "success1 = export_data_flexible(export_data, 'flexible_export.csv', 'csv', export_options);\n",
    "success2 = export_data_flexible(export_data, 'flexible_export.txt', 'txt', export_options);\n",
    "\n",
    "fprintf('Flexible export results: CSV=%d, TXT=%d\\n', success1, success2);\n",
    "\n",
    "% Clean up export files\n",
    "delete(formatted_file);\n",
    "delete(custom_csv);\n",
    "delete('flexible_export.csv');\n",
    "delete('flexible_export.txt');\n",
    "```\n",
    "\n",
    "## 8. Performance Optimization for File Operations\n",
    "\n",
    "```octave\n",
    "% Performance optimization for file operations\n",
    "fprintf('\\n=== Performance Optimization ===\\n');\n",
    "\n",
    "% Buffered file operations\n",
    "function write_performance_test(n_records)\n",
    "    % Compare different file writing approaches\n",
    "    % Input: n_records - number of records to write\n",
    "    \n",
    "    data = rand(n_records, 5);  % Random data\n",
    "    \n",
    "    % Method 1: Write line by line (slower)\n",
    "    filename1 = 'test_line_by_line.csv';\n",
    "    tic;\n",
    "    fid = fopen(filename1, 'w');\n",
    "    for i = 1:n_records\n",
    "        fprintf(fid, '%.6f,%.6f,%.6f,%.6f,%.6f\\n', data(i,:));\n",
    "    end\n",
    "    fclose(fid);\n",
    "    time1 = toc;\n",
    "    \n",
    "    % Method 2: Use vectorized csvwrite (faster)\n",
    "    filename2 = 'test_vectorized.csv';\n",
    "    tic;\n",
    "    csvwrite(filename2, data);\n",
    "    time2 = toc;\n",
    "    \n",
    "    fprintf('Writing %d records:\\n', n_records);\n",
    "    fprintf('  Line-by-line: %.4f seconds\\n', time1);\n",
    "    fprintf('  Vectorized: %.4f seconds\\n', time2);\n",
    "    fprintf('  Speedup: %.1fx\\n', time1/time2);\n",
    "    \n",
    "    % Clean up\n",
    "    delete(filename1);\n",
    "    delete(filename2);\n",
    "end\n",
    "\n",
    "% Test with moderate dataset size\n",
    "write_performance_test(1000);\n",
    "\n",
    "% Memory-mapped file simulation\n",
    "function demonstrate_chunked_processing()\n",
    "    % Demonstrate processing data in chunks\n",
    "    fprintf('Demonstrating chunked data processing:\\n');\n",
    "    \n",
    "    total_size = 5000;\n",
    "    chunk_size = 1000;\n",
    "    n_chunks = ceil(total_size / chunk_size);\n",
    "    \n",
    "    % Simulate processing large dataset in chunks\n",
    "    total_sum = 0;\n",
    "    total_elements = 0;\n",
    "    \n",
    "    for chunk = 1:n_chunks\n",
    "        % Simulate loading chunk\n",
    "        start_idx = (chunk - 1) * chunk_size + 1;\n",
    "        end_idx = min(chunk * chunk_size, total_size);\n",
    "        chunk_data = randn(end_idx - start_idx + 1, 3);\n",
    "        \n",
    "        % Process chunk\n",
    "        chunk_sum = sum(chunk_data(:));\n",
    "        chunk_elements = numel(chunk_data);\n",
    "        \n",
    "        total_sum = total_sum + chunk_sum;\n",
    "        total_elements = total_elements + chunk_elements;\n",
    "        \n",
    "        fprintf('  Chunk %d: processed %d elements\\n', chunk, chunk_elements);\n",
    "    end\n",
    "    \n",
    "    overall_mean = total_sum / total_elements;\n",
    "    fprintf('  Overall mean: %.6f\\n', overall_mean);\n",
    "end\n",
    "\n",
    "demonstrate_chunked_processing();\n",
    "\n",
    "% File format comparison\n",
    "function compare_file_formats()\n",
    "    % Compare different file formats for storage efficiency\n",
    "    fprintf('Comparing file formats:\\n');\n",
    "    \n",
    "    % Create test data\n",
    "    test_data = rand(100, 10);\n",
    "    \n",
    "    % MAT file\n",
    "    mat_file = 'test_data.mat';\n",
    "    save(mat_file, 'test_data');\n",
    "    mat_info = dir(mat_file);\n",
    "    \n",
    "    % CSV file  \n",
    "    csv_file = 'test_data.csv';\n",
    "    csvwrite(csv_file, test_data);\n",
    "    csv_info = dir(csv_file);\n",
    "    \n",
    "    % Binary file\n",
    "    bin_file = 'test_data.bin';\n",
    "    fid = fopen(bin_file, 'wb');\n",
    "    fwrite(fid, test_data, 'double');\n",
    "    fclose(fid);\n",
    "    bin_info = dir(bin_file);\n",
    "    \n",
    "    fprintf('  MAT file: %d bytes\\n', mat_info.bytes);\n",
    "    fprintf('  CSV file: %d bytes\\n', csv_info.bytes);\n",
    "    fprintf('  Binary file: %d bytes\\n', bin_info.bytes);\n",
    "    \n",
    "    % Clean up\n",
    "    delete(mat_file);\n",
    "    delete(csv_file);\n",
    "    delete(bin_file);\n",
    "end\n",
    "\n",
    "compare_file_formats();\n",
    "```\n",
    "\n",
    "## 9. Data Integrity and Backup\n",
    "\n",
    "```octave\n",
    "% Data integrity and backup strategies\n",
    "fprintf('\\n=== Data Integrity and Backup ===\\n');\n",
    "\n",
    "% Checksum calculation for data integrity\n",
    "function checksum = calculate_checksum(data)\n",
    "    % Calculate simple checksum for data integrity\n",
    "    % Input: data - numeric data array\n",
    "    % Output: checksum - calculated checksum\n",
    "    \n",
    "    % Simple checksum using sum and XOR operations\n",
    "    data_flat = data(:);\n",
    "    checksum = mod(sum(data_flat) + sum(data_flat.^2), 2^32);\n",
    "end\n",
    "\n",
    "% Create test data with checksum\n",
    "original_data = [1, 2, 3; 4, 5, 6; 7, 8, 9];\n",
    "original_checksum = calculate_checksum(original_data);\n",
    "\n",
    "fprintf('Original data checksum: %d\\n', original_checksum);\n",
    "\n",
    "% Simulate data corruption\n",
    "corrupted_data = original_data;\n",
    "corrupted_data(2, 2) = 999;  % Corrupt one element\n",
    "corrupted_checksum = calculate_checksum(corrupted_data);\n",
    "\n",
    "fprintf('Corrupted data checksum: %d\\n', corrupted_checksum);\n",
    "fprintf('Data integrity check: %s\\n', ...\n",
    "        iif(original_checksum == corrupted_checksum, 'PASSED', 'FAILED'));\n",
    "\n",
    "% Backup strategy implementation\n",
    "function backup_success = create_backup(data, base_filename, backup_dir)\n",
    "    % Create backup with timestamp\n",
    "    % Input: data - data to backup\n",
    "    %        base_filename - base name for files\n",
    "    %        backup_dir - backup directory\n",
    "    % Output: backup_success - success flag\n",
    "    \n",
    "    backup_success = false;\n",
    "    \n",
    "    try\n",
    "        % Create backup directory if it doesn't exist\n",
    "        if ~exist(backup_dir, 'dir')\n",
    "            mkdir(backup_dir);\n",
    "        end\n",
    "        \n",
    "        % Generate timestamped filename\n",
    "        timestamp = datestr(now(), 'yyyymmdd_HHMMSS');\n",
    "        backup_filename = fullfile(backup_dir, sprintf('%s_%s.mat', base_filename, timestamp));\n",
    "        \n",
    "        % Save with metadata\n",
    "        save_time = now();\n",
    "        data_checksum = calculate_checksum(data);\n",
    "        save(backup_filename, 'data', 'save_time', 'data_checksum');\n",
    "        \n",
    "        fprintf('Backup created: %s\\n', backup_filename);\n",
    "        backup_success = true;\n",
    "        \n",
    "    catch me\n",
    "        fprintf('Backup failed: %s\\n', me.message);\n",
    "    end\n",
    "end\n",
    "\n",
    "% Test backup system\n",
    "backup_dir = 'backups';\n",
    "success = create_backup(original_data, 'test_data', backup_dir);\n",
    "\n",
    "% Backup verification\n",
    "function verify_success = verify_backup(backup_filename)\n",
    "    % Verify backup integrity\n",
    "    % Input: backup_filename - path to backup file\n",
    "    % Output: verify_success - verification result\n",
    "    \n",
    "    verify_success = false;\n",
    "    \n",
    "    try\n",
    "        backup_data = load(backup_filename);\n",
    "        \n",
    "        % Verify checksum\n",
    "        calculated_checksum = calculate_checksum(backup_data.data);\n",
    "        stored_checksum = backup_data.data_checksum;\n",
    "        \n",
    "        if calculated_checksum == stored_checksum\n",
    "            fprintf('Backup verification: PASSED\\n');\n",
    "            verify_success = true;\n",
    "        else\n",
    "            fprintf('Backup verification: FAILED (checksum mismatch)\\n');\n",
    "        end\n",
    "        \n",
    "    catch me\n",
    "        fprintf('Backup verification failed: %s\\n', me.message);\n",
    "    end\n",
    "end\n",
    "\n",
    "% Find and verify recent backup\n",
    "if exist(backup_dir, 'dir')\n",
    "    backup_files = dir(fullfile(backup_dir, '*.mat'));\n",
    "    if ~isempty(backup_files)\n",
    "        latest_backup = fullfile(backup_dir, backup_files(end).name);\n",
    "        verify_backup(latest_backup);\n",
    "    end\n",
    "    \n",
    "    % Clean up backup directory\n",
    "    rmdir(backup_dir, 's');\n",
    "end\n",
    "```\n",
    "\n",
    "## 10. Real-World Applications\n",
    "\n",
    "```octave\n",
    "% Real-world data handling applications\n",
    "fprintf('\\n=== Real-World Applications ===\\n');\n",
    "\n",
    "% Application 1: Log file analysis\n",
    "function analyze_log_data()\n",
    "    % Simulate log file analysis\n",
    "    fprintf('Log File Analysis Simulation:\\n');\n",
    "    \n",
    "    % Create simulated log data\n",
    "    log_file = 'system.log';\n",
    "    fid = fopen(log_file, 'w');\n",
    "    \n",
    "    levels = {'INFO', 'WARNING', 'ERROR', 'DEBUG'};\n",
    "    messages = {'System started', 'Memory usage high', 'Connection failed', 'Processing data'};\n",
    "    \n",
    "    for i = 1:20\n",
    "        timestamp = datestr(now() - rand()*7, 'yyyy-mm-dd HH:MM:SS');\n",
    "        level = levels{randi(4)};\n",
    "        message = messages{randi(4)};\n",
    "        fprintf(fid, '%s [%s] %s\\n', timestamp, level, message);\n",
    "    end\n",
    "    fclose(fid);\n",
    "    \n",
    "    % Analyze log file\n",
    "    fid = fopen(log_file, 'r');\n",
    "    log_stats = struct('INFO', 0, 'WARNING', 0, 'ERROR', 0, 'DEBUG', 0);\n",
    "    \n",
    "    while ~feof(fid)\n",
    "        line = fgetl(fid);\n",
    "        if ischar(line)\n",
    "            for j = 1:length(levels)\n",
    "                if contains(line, levels{j})\n",
    "                    log_stats.(levels{j}) = log_stats.(levels{j}) + 1;\n",
    "                    break;\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    fclose(fid);\n",
    "    \n",
    "    fprintf('  Log analysis results:\\n');\n",
    "    fields = fieldnames(log_stats);\n",
    "    for i = 1:length(fields)\n",
    "        fprintf('    %s: %d entries\\n', fields{i}, log_stats.(fields{i}));\n",
    "    end\n",
    "    \n",
    "    delete(log_file);\n",
    "end\n",
    "\n",
    "analyze_log_data();\n",
    "\n",
    "% Application 2: Sensor data processing\n",
    "function process_sensor_data()\n",
    "    % Simulate sensor data processing pipeline\n",
    "    fprintf('Sensor Data Processing Simulation:\\n');\n",
    "    \n",
    "    % Generate synthetic sensor data\n",
    "    time_points = 1000;\n",
    "    time = linspace(0, 100, time_points);\n",
    "    \n",
    "    % Multiple sensors with different characteristics\n",
    "    sensor1 = 10 + 2*sin(2*pi*time/10) + 0.5*randn(size(time));  % Temperature\n",
    "    sensor2 = 50 + 10*cos(2*pi*time/15) + randn(size(time));     % Humidity  \n",
    "    sensor3 = 1013 + 5*sin(2*pi*time/20) + 0.2*randn(size(time)); % Pressure\n",
    "    \n",
    "    % Introduce some bad data\n",
    "    bad_indices = randi(time_points, 1, 20);\n",
    "    sensor1(bad_indices(1:5)) = -999;     % Missing values\n",
    "    sensor2(bad_indices(6:10)) = NaN;     % NaN values\n",
    "    sensor3(bad_indices(11:15)) = Inf;    % Infinite values\n",
    "    \n",
    "    % Create sensor data structure\n",
    "    sensor_data = struct();\n",
    "    sensor_data.time = time;\n",
    "    sensor_data.temperature = sensor1;\n",
    "    sensor_data.humidity = sensor2;  \n",
    "    sensor_data.pressure = sensor3;\n",
    "    \n",
    "    % Data validation and cleaning\n",
    "    [clean_temp, temp_report] = clean_dataset(sensor_data.temperature', -999);\n",
    "    [clean_hum, hum_report] = clean_dataset(sensor_data.humidity', -999);\n",
    "    [clean_press, press_report] = clean_dataset(sensor_data.pressure', -999);\n",
    "    \n",
    "    fprintf('  Sensor data cleaning results:\\n');\n",
    "    fprintf('    Temperature: %s, %.1f%% data retained\\n', ...\n",
    "            temp_report.strategy, (1-temp_report.data_loss_percent/100)*100);\n",
    "    fprintf('    Humidity: %s, %.1f%% data retained\\n', ...\n",
    "            hum_report.strategy, (1-hum_report.data_loss_percent/100)*100);\n",
    "    fprintf('    Pressure: %s, %.1f%% data retained\\n', ...\n",
    "            press_report.strategy, (1-press_report.data_loss_percent/100)*100);\n",
    "    \n",
    "    % Calculate statistics\n",
    "    fprintf('  Sensor statistics (after cleaning):\\n');\n",
    "    fprintf('    Temperature: mean=%.1f°C, std=%.2f°C\\n', mean(clean_temp), std(clean_temp));\n",
    "    fprintf('    Humidity: mean=%.1f%%, std=%.2f%%\\n', mean(clean_hum), std(clean_hum));\n",
    "    fprintf('    Pressure: mean=%.1f hPa, std=%.2f hPa\\n', mean(clean_press), std(clean_press));\n",
    "end\n",
    "\n",
    "process_sensor_data();\n",
    "\n",
    "% Application 3: Batch data processing\n",
    "function batch_process_files()\n",
    "    % Simulate batch processing of multiple data files\n",
    "    fprintf('Batch Data Processing Simulation:\\n');\n",
    "    \n",
    "    n_files = 5;\n",
    "    batch_results = struct('filenames', {}, 'means', [], 'stds', [], 'sizes', []);\n",
    "    \n",
    "    for i = 1:n_files\n",
    "        % Create temporary data file\n",
    "        filename = sprintf('batch_data_%d.csv', i);\n",
    "        data = randn(randi([50, 200]), 3) * (i * 2);  % Different scales\n",
    "        csvwrite(filename, data);\n",
    "        \n",
    "        % Process file\n",
    "        loaded_data = csvread(filename);\n",
    "        file_mean = mean(loaded_data(:));\n",
    "        file_std = std(loaded_data(:));\n",
    "        file_size = numel(loaded_data);\n",
    "        \n",
    "        % Store results\n",
    "        batch_results.filenames{i} = filename;\n",
    "        batch_results.means(i) = file_mean;\n",
    "        batch_results.stds(i) = file_std;  \n",
    "        batch_results.sizes(i) = file_size;\n",
    "        \n",
    "        fprintf('  Processed %s: mean=%.3f, std=%.3f, size=%d\\n', ...\n",
    "                filename, file_mean, file_std, file_size);\n",
    "        \n",
    "        % Clean up\n",
    "        delete(filename);\n",
    "    end\n",
    "    \n",
    "    % Aggregate results\n",
    "    overall_mean = mean(batch_results.means);\n",
    "    overall_std = mean(batch_results.stds);\n",
    "    total_elements = sum(batch_results.sizes);\n",
    "    \n",
    "    fprintf('  Batch processing summary:\\n');\n",
    "    fprintf('    Files processed: %d\\n', n_files);\n",
    "    fprintf('    Average mean: %.3f\\n', overall_mean);\n",
    "    fprintf('    Average std: %.3f\\n', overall_std);\n",
    "    fprintf('    Total elements: %d\\n', total_elements);\n",
    "end\n",
    "\n",
    "batch_process_files();\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "**Data Handling & File I/O Mastery Completed:**\n",
    "\n",
    "This comprehensive notebook covered all essential aspects of data handling and file operations:\n",
    "\n",
    "- ✅ **Basic File I/O**: Text files, binary files, reading/writing operations\n",
    "- ✅ **CSV Operations**: Import/export, parsing mixed data, manual CSV handling  \n",
    "- ✅ **MAT Files**: Saving/loading variables, partial loading, file information\n",
    "- ✅ **Large Datasets**: Chunked processing, memory-efficient techniques\n",
    "- ✅ **Data Import**: Multiple formats (TSV, fixed-width, JSON-like)\n",
    "- ✅ **Data Cleaning**: Missing values, outliers, validation, imputation\n",
    "- ✅ **Data Export**: Formatted output, flexible export functions\n",
    "- ✅ **Performance**: Optimization strategies, format comparisons\n",
    "- ✅ **Data Integrity**: Checksums, backup strategies, verification\n",
    "- ✅ **Real Applications**: Log analysis, sensor data, batch processing\n",
    "\n",
    "**Key Performance Insights:**\n",
    "1. **Vectorized Operations**: Use csvwrite/csvread for better performance\n",
    "2. **Memory Management**: Process large datasets in chunks\n",
    "3. **Data Validation**: Always validate and clean data before analysis\n",
    "4. **Format Selection**: Choose appropriate formats based on data types and size\n",
    "\n",
    "**Best Practices Established:**\n",
    "- Always validate input data and handle missing values appropriately\n",
    "- Implement proper error handling for file operations\n",
    "- Use checksums for data integrity verification\n",
    "- Create automated backup and recovery strategies\n",
    "- Optimize file I/O for performance with large datasets\n",
    "\n",
    "**Real-World Impact:**\n",
    "- Scientific data analysis pipelines\n",
    "- Business intelligence and reporting systems\n",
    "- IoT sensor data processing\n",
    "- Quality control and monitoring applications\n",
    "- Research data management and archival\n",
    "\n",
    "**Next Steps:**\n",
    "- Apply these techniques to domain-specific datasets\n",
    "- Explore advanced file formats and databases\n",
    "- Build automated data processing pipelines\n",
    "- Proceed to `06_plotting_2d_3d.ipynb` for data visualization\n",
    "\n",
    "Your data handling expertise is now enterprise-ready! 📊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
