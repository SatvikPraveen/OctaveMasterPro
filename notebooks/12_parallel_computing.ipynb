{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12_parallel_computing\n",
    "Multicore tasks, parfor-equivalents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% Content to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File: notebooks/12_parallel_computing.ipynb\n",
    "\n",
    "# OctaveMasterPro: Parallel Computing\n",
    "\n",
    "Master parallel and distributed computing! This final notebook covers multicore processing, parallel algorithms, distributed computing concepts, and performance optimization techniques for large-scale computational problems.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand parallel computing concepts and paradigms\n",
    "- Implement multicore algorithms and parallel processing\n",
    "- Apply distributed computing principles\n",
    "- Optimize parallel performance and scalability\n",
    "- Master advanced parallel programming patterns\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Parallel Computing Fundamentals\n",
    "\n",
    "```octave\n",
    "% Parallel computing concepts and basics\n",
    "fprintf('=== Parallel Computing Fundamentals ===\\n');\n",
    "\n",
    "fprintf('Note: Octave has limited built-in parallel processing.\\n');\n",
    "fprintf('This notebook demonstrates concepts and simulates parallel execution.\\n\\n');\n",
    "\n",
    "% Parallel algorithm simulation framework\n",
    "fprintf('1. Parallel Execution Simulation:\\n');\n",
    "\n",
    "function obj = ParallelExecutor(num_workers)\n",
    "    % Simulate parallel execution environment\n",
    "    if nargin < 1, num_workers = 4; end\n",
    "    \n",
    "    obj.num_workers = num_workers;\n",
    "    obj.task_queue = {};\n",
    "    obj.results = {};\n",
    "    obj.execution_times = [];\n",
    "    obj.class_name = 'ParallelExecutor';\n",
    "    \n",
    "    obj.add_task = @(task_func, task_data) add_parallel_task(obj, task_func, task_data);\n",
    "    obj.execute_all = @() execute_parallel_tasks(obj);\n",
    "    obj.get_results = @() obj.results;\n",
    "    obj.get_performance = @() get_parallel_performance(obj);\n",
    "end\n",
    "\n",
    "function add_parallel_task(obj, task_func, task_data)\n",
    "    task = struct('func', task_func, 'data', task_data, 'id', length(obj.task_queue) + 1);\n",
    "    obj.task_queue{end+1} = task;\n",
    "    fprintf('   Added task %d to queue\\n', task.id);\n",
    "end\n",
    "\n",
    "function execute_parallel_tasks(obj)\n",
    "    fprintf('   Executing %d tasks on %d workers\\n', length(obj.task_queue), obj.num_workers);\n",
    "    \n",
    "    obj.results = cell(length(obj.task_queue), 1);\n",
    "    obj.execution_times = zeros(length(obj.task_queue), 1);\n",
    "    \n",
    "    % Simulate parallel execution by batching tasks\n",
    "    batch_size = ceil(length(obj.task_queue) / obj.num_workers);\n",
    "    \n",
    "    total_start = tic;\n",
    "    \n",
    "    for batch = 1:obj.num_workers\n",
    "        batch_start = (batch - 1) * batch_size + 1;\n",
    "        batch_end = min(batch * batch_size, length(obj.task_queue));\n",
    "        \n",
    "        if batch_start > length(obj.task_queue)\n",
    "            break;\n",
    "        end\n",
    "        \n",
    "        fprintf('   Worker %d processing tasks %d-%d\\n', batch, batch_start, batch_end);\n",
    "        \n",
    "        # Simulate parallel execution (in reality, tasks would run simultaneously)\n",
    "        for task_idx = batch_start:batch_end\n",
    "            task = obj.task_queue{task_idx};\n",
    "            \n",
    "            task_start = tic;\n",
    "            obj.results{task_idx} = task.func(task.data);\n",
    "            obj.execution_times(task_idx) = toc(task_start);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    total_time = toc(total_start);\n",
    "    fprintf('   Total execution time: %.4f seconds\\n', total_time);\n",
    "end\n",
    "\n",
    "function perf = get_parallel_performance(obj)\n",
    "    perf = struct();\n",
    "    perf.total_tasks = length(obj.task_queue);\n",
    "    perf.workers = obj.num_workers;\n",
    "    perf.individual_times = obj.execution_times;\n",
    "    perf.total_time = sum(obj.execution_times);\n",
    "    perf.average_time = mean(obj.execution_times);\n",
    "    perf.max_time = max(obj.execution_times);\n",
    "    perf.min_time = min(obj.execution_times);\n",
    "    \n",
    "    % Simulate parallel speedup (actual time would be max of concurrent batches)\n",
    "    sequential_time = sum(obj.execution_times);\n",
    "    simulated_parallel_time = max(obj.execution_times) * ceil(perf.total_tasks / perf.workers);\n",
    "    perf.speedup = sequential_time / simulated_parallel_time;\n",
    "    perf.efficiency = perf.speedup / perf.workers;\n",
    "    \n",
    "    fprintf('   Performance metrics:\\n');\n",
    "    fprintf('     Sequential time: %.4f seconds\\n', sequential_time);\n",
    "    fprintf('     Parallel time (simulated): %.4f seconds\\n', simulated_parallel_time);\n",
    "    fprintf('     Speedup: %.2fx\\n', perf.speedup);\n",
    "    fprintf('     Efficiency: %.1f%%\\n', perf.efficiency * 100);\n",
    "end\n",
    "\n",
    "% Test parallel execution simulation\n",
    "parallel_exec = ParallelExecutor(4);\n",
    "\n",
    "# Define sample computational tasks\n",
    "compute_pi = @(n) estimate_pi_monte_carlo(n);\n",
    "matrix_multiply = @(data) data.A * data.B;\n",
    "numerical_integration = @(data) simpson_integrate(data.func, data.a, data.b, data.n);\n",
    "\n",
    "function pi_est = estimate_pi_monte_carlo(n)\n",
    "    % Monte Carlo estimation of Ï€\n",
    "    x = rand(n, 1);\n",
    "    y = rand(n, 1);\n",
    "    inside_circle = sum(x.^2 + y.^2 <= 1);\n",
    "    pi_est = 4 * inside_circle / n;\n",
    "end\n",
    "\n",
    "function integral = simpson_integrate(func, a, b, n)\n",
    "    % Simpson's rule integration\n",
    "    if mod(n, 2) == 1, n = n + 1; end  % Ensure even number of intervals\n",
    "    \n",
    "    h = (b - a) / n;\n",
    "    x = a:h:b;\n",
    "    y = func(x);\n",
    "    \n",
    "    integral = h/3 * (y(1) + 4*sum(y(2:2:end-1)) + 2*sum(y(3:2:end-2)) + y(end));\n",
    "end\n",
    "\n",
    "% Add tasks to parallel executor\n",
    "parallel_exec.add_task(compute_pi, 100000);\n",
    "parallel_exec.add_task(compute_pi, 200000);\n",
    "parallel_exec.add_task(compute_pi, 150000);\n",
    "\n",
    "matrix_data1 = struct('A', rand(100, 80), 'B', rand(80, 60));\n",
    "matrix_data2 = struct('A', rand(120, 90), 'B', rand(90, 70));\n",
    "parallel_exec.add_task(matrix_multiply, matrix_data1);\n",
    "parallel_exec.add_task(matrix_multiply, matrix_data2);\n",
    "\n",
    "integ_data1 = struct('func', @sin, 'a', 0, 'b', pi, 'n', 1000);\n",
    "integ_data2 = struct('func', @(x) exp(-x.^2), 'a', -2, 'b', 2, 'n', 2000);\n",
    "parallel_exec.add_task(numerical_integration, integ_data1);\n",
    "parallel_exec.add_task(numerical_integration, integ_data2);\n",
    "\n",
    "% Execute all tasks\n",
    "parallel_exec.execute_all();\n",
    "\n",
    "results = parallel_exec.get_results();\n",
    "fprintf('   Sample results:\\n');\n",
    "fprintf('     Ï€ estimates: %.6f, %.6f, %.6f\\n', results{1}, results{2}, results{3});\n",
    "fprintf('     Integration results: %.6f, %.6f\\n', results{6}, results{7});\n",
    "\n",
    "parallel_exec.get_performance();\n",
    "```\n",
    "\n",
    "## 2. Parallel Algorithms and Patterns\n",
    "\n",
    "```octave\n",
    "% Parallel algorithm implementations\n",
    "fprintf('\\n=== Parallel Algorithms and Patterns ===\\n');\n",
    "\n",
    "% Parallel reduction\n",
    "fprintf('1. Parallel Reduction:\\n');\n",
    "\n",
    "function result = parallel_reduction(data, operation, num_workers)\n",
    "    % Parallel reduction using divide-and-conquer\n",
    "    % Input: data - input array, operation - reduction operation, num_workers\n",
    "    % Output: result - reduced result\n",
    "    \n",
    "    if nargin < 3, num_workers = 4; end\n",
    "    \n",
    "    n = length(data);\n",
    "    chunk_size = ceil(n / num_workers);\n",
    "    \n",
    "    fprintf('   Parallel reduction: %d elements, %d workers\\n', n, num_workers);\n",
    "    \n",
    "    % Phase 1: Local reductions\n",
    "    local_results = zeros(num_workers, 1);\n",
    "    \n",
    "    for worker = 1:num_workers\n",
    "        start_idx = (worker - 1) * chunk_size + 1;\n",
    "        end_idx = min(worker * chunk_size, n);\n",
    "        \n",
    "        if start_idx <= n\n",
    "            chunk = data(start_idx:end_idx);\n",
    "            local_results(worker) = apply_reduction(chunk, operation);\n",
    "            fprintf('     Worker %d: indices %d-%d, result = %.6f\\n', ...\n",
    "                    worker, start_idx, end_idx, local_results(worker));\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Phase 2: Global reduction\n",
    "    result = apply_reduction(local_results(local_results ~= 0), operation);\n",
    "    fprintf('   Final result: %.6f\\n', result);\n",
    "end\n",
    "\n",
    "function result = apply_reduction(data, operation)\n",
    "    switch lower(operation)\n",
    "        case 'sum'\n",
    "            result = sum(data);\n",
    "        case 'max'\n",
    "            result = max(data);\n",
    "        case 'min'\n",
    "            result = min(data);\n",
    "        case 'product'\n",
    "            result = prod(data);\n",
    "        otherwise\n",
    "            error('Unknown reduction operation: %s', operation);\n",
    "    end\n",
    "end\n",
    "\n",
    "% Test parallel reduction\n",
    "test_data = rand(10000, 1) * 100;\n",
    "\n",
    "serial_sum = sum(test_data);\n",
    "parallel_sum = parallel_reduction(test_data, 'sum', 4);\n",
    "fprintf('   Reduction verification: serial=%.6f, parallel=%.6f, diff=%.2e\\n', ...\n",
    "        serial_sum, parallel_sum, abs(serial_sum - parallel_sum));\n",
    "\n",
    "% Parallel matrix operations\n",
    "fprintf('\\n2. Parallel Matrix Operations:\\n');\n",
    "\n",
    "function C = parallel_matrix_multiply(A, B, block_size)\n",
    "    % Block-parallel matrix multiplication\n",
    "    % Input: A, B - matrices to multiply, block_size - block dimensions\n",
    "    % Output: C - result matrix A*B\n",
    "    \n",
    "    [m, k1] = size(A);\n",
    "    [k2, n] = size(B);\n",
    "    \n",
    "    if k1 ~= k2\n",
    "        error('Matrix dimensions incompatible');\n",
    "    end\n",
    "    k = k1;\n",
    "    \n",
    "    if nargin < 3\n",
    "        block_size = min(64, min([m, n, k]));\n",
    "    end\n",
    "    \n",
    "    fprintf('   Parallel matrix multiply: (%dx%d) * (%dx%d), block_size=%d\\n', ...\n",
    "            m, k, k, n, block_size);\n",
    "    \n",
    "    C = zeros(m, n);\n",
    "    \n",
    "    % Number of block operations\n",
    "    blocks_i = ceil(m / block_size);\n",
    "    blocks_j = ceil(n / block_size);\n",
    "    blocks_k = ceil(k / block_size);\n",
    "    total_blocks = blocks_i * blocks_j * blocks_k;\n",
    "    \n",
    "    fprintf('   Processing %d blocks (%dx%dx%d)\\n', total_blocks, blocks_i, blocks_j, blocks_k);\n",
    "    \n",
    "    block_count = 0;\n",
    "    \n",
    "    for i = 1:block_size:m\n",
    "        i_end = min(i + block_size - 1, m);\n",
    "        for j = 1:block_size:n\n",
    "            j_end = min(j + block_size - 1, n);\n",
    "            for kk = 1:block_size:k\n",
    "                kk_end = min(kk + block_size - 1, k);\n",
    "                \n",
    "                % This block operation could be executed in parallel\n",
    "                C(i:i_end, j:j_end) = C(i:i_end, j:j_end) + ...\n",
    "                    A(i:i_end, kk:kk_end) * B(kk:kk_end, j:j_end);\n",
    "                \n",
    "                block_count = block_count + 1;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    fprintf('   Completed %d block operations\\n', block_count);\n",
    "end\n",
    "\n",
    "% Test parallel matrix multiplication\n",
    "A_par = rand(200, 150);\n",
    "B_par = rand(150, 180);\n",
    "\n",
    "tic;\n",
    "C_parallel = parallel_matrix_multiply(A_par, B_par, 50);\n",
    "parallel_mm_time = toc;\n",
    "\n",
    "tic;\n",
    "C_builtin = A_par * B_par;\n",
    "builtin_mm_time = toc;\n",
    "\n",
    "mm_error = max(abs(C_parallel(:) - C_builtin(:)));\n",
    "fprintf('   Matrix multiply verification: error=%.2e\\n', mm_error);\n",
    "fprintf('   Timing: parallel=%.4fs, builtin=%.4fs\\n', parallel_mm_time, builtin_mm_time);\n",
    "\n",
    "% Parallel sorting algorithms\n",
    "fprintf('\\n3. Parallel Sorting:\\n');\n",
    "\n",
    "function sorted_data = parallel_merge_sort(data, num_workers)\n",
    "    % Parallel merge sort implementation\n",
    "    % Input: data - array to sort, num_workers - number of parallel workers\n",
    "    % Output: sorted_data - sorted array\n",
    "    \n",
    "    if nargin < 2, num_workers = 4; end\n",
    "    \n",
    "    n = length(data);\n",
    "    chunk_size = ceil(n / num_workers);\n",
    "    \n",
    "    fprintf('   Parallel merge sort: %d elements, %d workers\\n', n, num_workers);\n",
    "    \n",
    "    % Phase 1: Sort chunks in parallel\n",
    "    sorted_chunks = cell(num_workers, 1);\n",
    "    \n",
    "    for worker = 1:num_workers\n",
    "        start_idx = (worker - 1) * chunk_size + 1;\n",
    "        end_idx = min(worker * chunk_size, n);\n",
    "        \n",
    "        if start_idx <= n\n",
    "            chunk = data(start_idx:end_idx);\n",
    "            sorted_chunks{worker} = sort(chunk);  % Local sort\n",
    "            fprintf('     Worker %d sorted chunk of size %d\\n', worker, length(chunk));\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    % Phase 2: Merge sorted chunks\n",
    "    sorted_data = [];\n",
    "    for worker = 1:num_workers\n",
    "        if ~isempty(sorted_chunks{worker})\n",
    "            sorted_data = merge_sorted_arrays(sorted_data, sorted_chunks{worker});\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    fprintf('   Parallel merge sort completed\\n');\n",
    "end\n",
    "\n",
    "function merged = merge_sorted_arrays(arr1, arr2)\n",
    "    % Merge two sorted arrays\n",
    "    if isempty(arr1), merged = arr2; return; end\n",
    "    if isempty(arr2), merged = arr1; return; end\n",
    "    \n",
    "    merged = zeros(1, length(arr1) + length(arr2));\n",
    "    i = 1; j = 1; k = 1;\n",
    "    \n",
    "    while i <= length(arr1) && j <= length(arr2)\n",
    "        if arr1(i) <= arr2(j)\n",
    "            merged(k) = arr1(i);\n",
    "            i = i + 1;\n",
    "        else\n",
    "            merged(k) = arr2(j);\n",
    "            j = j + 1;\n",
    "        end\n",
    "        k = k + 1;\n",
    "    end\n",
    "    \n",
    "    % Copy remaining elements\n",
    "    while i <= length(arr1)\n",
    "        merged(k) = arr1(i);\n",
    "        i = i + 1;\n",
    "        k = k + 1;\n",
    "    end\n",
    "    \n",
    "    while j <= length(arr2)\n",
    "        merged(k) = arr2(j);\n",
    "        j = j + 1;\n",
    "        k = k + 1;\n",
    "    end\n",
    "end\n",
    "\n",
    "% Test parallel sorting\n",
    "sort_data = rand(5000, 1) * 1000;\n",
    "\n",
    "tic;\n",
    "parallel_sorted = parallel_merge_sort(sort_data, 6);\n",
    "parallel_sort_time = toc;\n",
    "\n",
    "tic;\n",
    "builtin_sorted = sort(sort_data);\n",
    "builtin_sort_time = toc;\n",
    "\n",
    "sort_error = max(abs(parallel_sorted' - builtin_sorted));\n",
    "fprintf('   Sort verification: error=%.2e\\n', sort_error);\n",
    "fprintf('   Timing: parallel=%.4fs, builtin=%.4fs\\n', parallel_sort_time, builtin_sort_time);\n",
    "```\n",
    "\n",
    "## 3. Load Balancing and Scheduling\n",
    "\n",
    "```octave\n",
    "% Load balancing and task scheduling\n",
    "fprintf('\\n=== Load Balancing and Scheduling ===\\n');\n",
    "\n",
    "% Dynamic load balancing\n",
    "fprintf('1. Dynamic Load Balancing:\\n');\n",
    "\n",
    "function obj = LoadBalancer(num_workers)\n",
    "    % Dynamic load balancer for parallel tasks\n",
    "    obj.num_workers = num_workers;\n",
    "    obj.worker_loads = zeros(num_workers, 1);\n",
    "    obj.task_assignments = {};\n",
    "    obj.completion_times = [];\n",
    "    obj.class_name = 'LoadBalancer';\n",
    "    \n",
    "    obj.assign_task = @(task_cost) assign_task_dynamic(obj, task_cost);\n",
    "    obj.complete_task = @(worker_id, completion_time) complete_worker_task(obj, worker_id, completion_time);\n",
    "    obj.get_balance_stats = @() get_load_balance_stats(obj);\n",
    "end\n",
    "\n",
    "function worker_id = assign_task_dynamic(obj, task_cost)\n",
    "    % Assign task to worker with minimum current load\n",
    "    [~, worker_id] = min(obj.worker_loads);\n",
    "    \n",
    "    obj.worker_loads(worker_id) = obj.worker_loads(worker_id) + task_cost;\n",
    "    \n",
    "    if length(obj.task_assignments) < worker_id\n",
    "        obj.task_assignments{worker_id} = [];\n",
    "    end\n",
    "    obj.task_assignments{worker_id}(end+1) = task_cost;\n",
    "    \n",
    "    fprintf('   Assigned task (cost=%.2f) to worker %d (new load: %.2f)\\n', ...\n",
    "            task_cost, worker_id, obj.worker_loads(worker_id));\n",
    "end\n",
    "\n",
    "function complete_worker_task(obj, worker_id, completion_time)\n",
    "    % Mark task completion and update worker load\n",
    "    if ~isempty(obj.task_assignments{worker_id})\n",
    "        completed_cost = obj.task_assignments{worker_id}(1);\n",
    "        obj.task_assignments{worker_id}(1) = [];\n",
    "        obj.worker_loads(worker_id) = obj.worker_loads(worker_id) - completed_cost;\n",
    "        obj.completion_times(end+1) = completion_time;\n",
    "        \n",
    "        fprintf('   Worker %d completed task (remaining load: %.2f)\\n', ...\n",
    "                worker_id, obj.worker_loads(worker_id));\n",
    "    end\n",
    "end\n",
    "\n",
    "function stats = get_load_balance_stats(obj)\n",
    "    stats = struct();\n",
    "    stats.worker_loads = obj.worker_loads;\n",
    "    stats.total_load = sum(obj.worker_loads);\n",
    "    stats.average_load = stats.total_load / obj.num_workers;\n",
    "    stats.load_imbalance = max(obj.worker_loads) - min(obj.worker_loads);\n",
    "    stats.load_variance = var(obj.worker_loads);\n",
    "    \n",
    "    fprintf('   Load balance statistics:\\n');\n",
    "    fprintf('     Total load: %.2f\\n', stats.total_load);\n",
    "    fprintf('     Average load per worker: %.2f\\n', stats.average_load);\n",
    "    fprintf('     Load imbalance: %.2f\\n', stats.load_imbalance);\n",
    "    fprintf('     Load variance: %.4f\\n', stats.load_variance);\n",
    "    \n",
    "    for i = 1:obj.num_workers\n",
    "        fprintf('     Worker %d load: %.2f\\n', i, obj.worker_loads(i));\n",
    "    end\n",
    "end\n",
    "\n",
    "% Test dynamic load balancing\n",
    "lb = LoadBalancer(4);\n",
    "\n",
    "# Simulate tasks with varying computational costs\n",
    "task_costs = [1.5, 3.2, 0.8, 2.1, 4.0, 1.2, 2.8, 0.5, 3.5, 1.8];\n",
    "\n",
    "for i = 1:length(task_costs)\n",
    "    lb.assign_task(task_costs(i));\n",
    "end\n",
    "\n",
    "lb.get_balance_stats();\n",
    "\n",
    "% Work-stealing algorithm simulation\n",
    "fprintf('\\n2. Work-Stealing Algorithm:\\n');\n",
    "\n",
    "function obj = WorkStealingScheduler(num_workers)\n",
    "    % Work-stealing scheduler simulation\n",
    "    obj.num_workers = num_workers;\n",
    "    obj.worker_queues = cell(num_workers, 1);\n",
    "    obj.worker_busy = false(num_workers, 1);\n",
    "    obj.steal_attempts = 0;\n",
    "    obj.successful_steals = 0;\n",
    "    obj.class_name = 'WorkStealingScheduler';\n",
    "    \n",
    "    for i = 1:num_workers\n",
    "        obj.worker_queues{i} = [];\n",
    "    end\n",
    "    \n",
    "    obj.add_task = @(worker_id, task) add_task_to_worker(obj, worker_id, task);\n",
    "    obj.execute_step = @() execute_scheduling_step(obj);\n",
    "    obj.get_queue_sizes = @() get_worker_queue_sizes(obj);\n",
    "    obj.get_steal_stats = @() get_stealing_statistics(obj);\n",
    "end\n",
    "\n",
    "function add_task_to_worker(obj, worker_id, task)\n",
    "    obj.worker_queues{worker_id}(end+1) = task;\n",
    "    fprintf('   Added task %.2f to worker %d queue\\n', task, worker_id);\n",
    "end\n",
    "\n",
    "function execute_scheduling_step(obj)\n",
    "    % Execute one step of work-stealing scheduling\n",
    "    \n",
    "    for worker = 1:obj.num_workers\n",
    "        if ~obj.worker_busy(worker)\n",
    "            if ~isempty(obj.worker_queues{worker})\n",
    "                # Worker has local work\n",
    "                task = obj.worker_queues{worker}(1);\n",
    "                obj.worker_queues{worker}(1) = [];\n",
    "                obj.worker_busy(worker) = true;\n",
    "                \n",
    "                fprintf('   Worker %d executing local task %.2f\\n', worker, task);\n",
    "            else\n",
    "                % Worker is idle - attempt work stealing\n",
    "                victim = attempt_work_stealing(obj, worker);\n",
    "                if victim > 0\n",
    "                    obj.successful_steals = obj.successful_steals + 1;\n",
    "                    fprintf('   Worker %d stole work from worker %d\\n', worker, victim);\n",
    "                end\n",
    "                obj.steal_attempts = obj.steal_attempts + 1;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    % Simulate task completion (workers become available)\n",
    "    completion_probability = 0.3;  % 30% chance a busy worker completes\n",
    "    for worker = 1:obj.num_workers\n",
    "        if obj.worker_busy(worker) && rand() < completion_probability\n",
    "            obj.worker_busy(worker) = false;\n",
    "            fprintf('   Worker %d completed task\\n', worker);\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function victim_id = attempt_work_stealing(obj, thief_id)\n",
    "    % Attempt to steal work from another worker\n",
    "    victim_id = 0;\n",
    "    \n",
    "    % Randomly select potential victims\n",
    "    potential_victims = setdiff(1:obj.num_workers, thief_id);\n",
    "    potential_victims = potential_victims(randperm(length(potential_victims)));\n",
    "    \n",
    "    for victim = potential_victims\n",
    "        if length(obj.worker_queues{victim}) > 1  % Victim has work to steal\n",
    "            % Steal from the end of victim's queue (work-stealing from tail)\n",
    "            stolen_task = obj.worker_queues{victim}(end);\n",
    "            obj.worker_queues{victim}(end) = [];\n",
    "            obj.worker_queues{thief_id}(end+1) = stolen_task;\n",
    "            victim_id = victim;\n",
    "            break;\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function sizes = get_worker_queue_sizes(obj)\n",
    "    sizes = zeros(obj.num_workers, 1);\n",
    "    for i = 1:obj.num_workers\n",
    "        sizes(i) = length(obj.worker_queues{i});\n",
    "    end\n",
    "    \n",
    "    fprintf('   Queue sizes: ['); fprintf('%d ', sizes'); fprintf(']\\n');\n",
    "end\n",
    "\n",
    "function stats = get_stealing_statistics(obj)\n",
    "    stats = struct();\n",
    "    stats.steal_attempts = obj.steal_attempts;\n",
    "    stats.successful_steals = obj.successful_steals;\n",
    "    stats.steal_success_rate = obj.successful_steals / max(1, obj.steal_attempts);\n",
    "    \n",
    "    fprintf('   Work-stealing statistics:\\n');\n",
    "    fprintf('     Steal attempts: %d\\n', stats.steal_attempts);\n",
    "    fprintf('     Successful steals: %d\\n', stats.successful_steals);\n",
    "    fprintf('     Success rate: %.1f%%\\n', stats.steal_success_rate * 100);\n",
    "end\n",
    "\n",
    "% Test work-stealing scheduler\n",
    "ws = WorkStealingScheduler(3);\n",
    "\n",
    "% Initially distribute tasks unevenly\n",
    "ws.add_task(1, 2.5);\n",
    "ws.add_task(1, 1.8);\n",
    "ws.add_task(1, 3.2);\n",
    "ws.add_task(1, 1.5);\n",
    "\n",
    "ws.add_task(2, 0.8);\n",
    "\n",
    "% Worker 3 starts with no tasks\n",
    "\n",
    "fprintf('   Initial distribution:\\n');\n",
    "ws.get_queue_sizes();\n",
    "\n",
    "% Simulate several scheduling steps\n",
    "fprintf('   Executing work-stealing steps:\\n');\n",
    "for step = 1:8\n",
    "    fprintf('   Step %d:\\n', step);\n",
    "    ws.execute_step();\n",
    "    ws.get_queue_sizes();\n",
    "end\n",
    "\n",
    "ws.get_steal_stats();\n",
    "```\n",
    "\n",
    "## 4. Distributed Computing Concepts\n",
    "\n",
    "```octave\n",
    "% Distributed computing principles\n",
    "fprintf('\\n=== Distributed Computing Concepts ===\\n');\n",
    "\n",
    "% Message passing simulation\n",
    "fprintf('1. Message Passing Interface Simulation:\\n');\n",
    "\n",
    "function obj = MPISimulator(num_processes)\n",
    "    % Simulate MPI-style message passing\n",
    "    obj.num_processes = num_processes;\n",
    "    obj.message_queues = cell(num_processes, 1);\n",
    "    obj.process_states = cell(num_processes, 1);\n",
    "    obj.message_count = 0;\n",
    "    obj.class_name = 'MPISimulator';\n",
    "    \n",
    "    for i = 1:num_processes\n",
    "        obj.message_queues{i} = {};\n",
    "        obj.process_states{i} = struct('id', i, 'data', [], 'status', 'ready');\n",
    "    end\n",
    "    \n",
    "    obj.send = @(from, to, data) send_message(obj, from, to, data);\n",
    "    obj.receive = @(process_id) receive_message(obj, process_id);\n",
    "    obj.broadcast = @(root, data) broadcast_message(obj, root, data);\n",
    "    obj.gather = @(root) gather_data(obj, root);\n",
    "    obj.barrier = @() synchronization_barrier(obj);\n",
    "    obj.get_status = @() get_mpi_status(obj);\n",
    "end\n",
    "\n",
    "function send_message(obj, from, to, data)\n",
    "    if from < 1 || from > obj.num_processes || to < 1 || to > obj.num_processes\n",
    "        error('Invalid process ID');\n",
    "    end\n",
    "    \n",
    "    message = struct('from', from, 'data', data, 'timestamp', now());\n",
    "    obj.message_queues{to}{end+1} = message;\n",
    "    obj.message_count = obj.message_count + 1;\n",
    "    \n",
    "    fprintf('   Process %d -> Process %d: %s\\n', from, to, mat2str(data));\n",
    "end\n",
    "\n",
    "function [data, from] = receive_message(obj, process_id)\n",
    "    if isempty(obj.message_queues{process_id})\n",
    "        data = [];\n",
    "        from = -1;\n",
    "        fprintf('   Process %d: No messages in queue\\n', process_id);\n",
    "    else\n",
    "        message = obj.message_queues{process_id}{1};\n",
    "        obj.message_queues{process_id}(1) = [];\n",
    "        data = message.data;\n",
    "        from = message.from;\n",
    "        fprintf('   Process %d received from Process %d: %s\\n', ...\n",
    "                process_id, from, mat2str(data));\n",
    "    end\n",
    "end\n",
    "\n",
    "function broadcast_message(obj, root, data)\n",
    "    fprintf('   Broadcasting from Process %d: %s\\n', root, mat2str(data));\n",
    "    for i = 1:obj.num_processes\n",
    "        if i ~= root\n",
    "            obj.send(root, i, data);\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function gathered_data = gather_data(obj, root)\n",
    "    fprintf('   Gathering data to Process %d\\n', root);\n",
    "    gathered_data = cell(obj.num_processes, 1);\n",
    "    \n",
    "    % Root collects its own data\n",
    "    gathered_data{root} = obj.process_states{root}.data;\n",
    "    \n",
    "    # Other processes send data to root\n",
    "    for i = 1:obj.num_processes\n",
    "        if i ~= root\n",
    "            obj.send(i, root, obj.process_states{i}.data);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Root receives all data\n",
    "    for i = 1:obj.num_processes\n",
    "        if i ~= root\n",
    "            [data, ~] = obj.receive(root);\n",
    "            gathered_data{i} = data;\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function synchronization_barrier(obj)\n",
    "    fprintf('   Synchronization barrier - all processes wait\\n');\n",
    "    % In real MPI, all processes would wait here until all reach the barrier\n",
    "    for i = 1:obj.num_processes\n",
    "        obj.process_states{i}.status = 'synchronized';\n",
    "    end\n",
    "end\n",
    "\n",
    "function status = get_mpi_status(obj)\n",
    "    status = struct();\n",
    "    status.num_processes = obj.num_processes;\n",
    "    status.total_messages = obj.message_count;\n",
    "    \n",
    "    queue_lengths = zeros(obj.num_processes, 1);\n",
    "    for i = 1:obj.num_processes\n",
    "        queue_lengths(i) = length(obj.message_queues{i});\n",
    "    end\n",
    "    status.queue_lengths = queue_lengths;\n",
    "    \n",
    "    fprintf('   MPI Status: %d processes, %d messages sent\\n', ...\n",
    "            status.num_processes, status.total_messages);\n",
    "    fprintf('   Queue lengths: ['); fprintf('%d ', queue_lengths'); fprintf(']\\n');\n",
    "end\n",
    "\n",
    "% Test MPI simulation\n",
    "mpi = MPISimulator(4);\n",
    "\n",
    "% Set some data in processes\n",
    "for i = 1:4\n",
    "    mpi.process_states{i}.data = i * 10 + rand();\n",
    "end\n",
    "\n",
    "% Test point-to-point communication\n",
    "mpi.send(1, 2, [1, 2, 3]);\n",
    "mpi.send(3, 1, 'hello');\n",
    "mpi.receive(2);\n",
    "mpi.receive(1);\n",
    "\n",
    "% Test broadcast\n",
    "mpi.broadcast(1, [100, 200, 300]);\n",
    "\n",
    "# Test gather operation\n",
    "gathered = mpi.gather(1);\n",
    "fprintf('   Gathered data: ');\n",
    "for i = 1:length(gathered)\n",
    "    fprintf('P%d=%.2f ', i, gathered{i});\n",
    "end\n",
    "fprintf('\\n');\n",
    "\n",
    "mpi.barrier();\n",
    "mpi.get_status();\n",
    "\n",
    "% MapReduce paradigm simulation\n",
    "fprintf('\\n2. MapReduce Paradigm:\\n');\n",
    "\n",
    "function result = mapreduce_simulation(data, map_func, reduce_func, num_mappers, num_reducers)\n",
    "    % Simulate MapReduce computation\n",
    "    % Input: data - input data, map_func - mapper function, reduce_func - reducer function\n",
    "    % Output: result - final result\n",
    "    \n",
    "    fprintf('   MapReduce: %d elements, %d mappers, %d reducers\\n', ...\n",
    "            length(data), num_mappers, num_reducers);\n",
    "    \n",
    "    % Phase 1: Map\n",
    "    chunk_size = ceil(length(data) / num_mappers);\n",
    "    map_results = cell(num_mappers, 1);\n",
    "    \n",
    "    fprintf('   Map phase:\\n');\n",
    "    for mapper = 1:num_mappers\n",
    "        start_idx = (mapper - 1) * chunk_size + 1;\n",
    "        end_idx = min(mapper * chunk_size, length(data));\n",
    "        \n",
    "        if start_idx <= length(data)\n",
    "            chunk = data(start_idx:end_idx);\n",
    "            map_results{mapper} = map_func(chunk);\n",
    "            fprintf('     Mapper %d: processed %d elements\\n', mapper, length(chunk));\n",
    "        else\n",
    "            map_results{mapper} = [];\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Phase 2: Shuffle and Sort (simplified)\n",
    "    all_intermediate = [];\n",
    "    for i = 1:num_mappers\n",
    "        if ~isempty(map_results{i})\n",
    "            all_intermediate = [all_intermediate; map_results{i}(:)];\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    fprintf('   Shuffle phase: %d intermediate results\\n', length(all_intermediate));\n",
    "    \n",
    "    % Phase 3: Reduce\n",
    "    reducer_chunk_size = ceil(length(all_intermediate) / num_reducers);\n",
    "    reduce_results = cell(num_reducers, 1);\n",
    "    \n",
    "    fprintf('   Reduce phase:\\n');\n",
    "    for reducer = 1:num_reducers\n",
    "        start_idx = (reducer - 1) * reducer_chunk_size + 1;\n",
    "        end_idx = min(reducer * reducer_chunk_size, length(all_intermediate));\n",
    "        \n",
    "        if start_idx <= length(all_intermediate)\n",
    "            chunk = all_intermediate(start_idx:end_idx);\n",
    "            reduce_results{reducer} = reduce_func(chunk);\n",
    "            fprintf('     Reducer %d: processed %d elements, result=%.4f\\n', ...\n",
    "                    reducer, length(chunk), reduce_results{reducer});\n",
    "        else\n",
    "            reduce_results{reducer} = 0;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Final aggregation\n",
    "    result = sum([reduce_results{:}]);\n",
    "    fprintf('   Final result: %.6f\\n', result);\n",
    "end\n",
    "\n",
    "% Test MapReduce with word count simulation\n",
    "word_count_data = randi([1, 100], 10000, 1);  % Simulate word IDs\n",
    "\n",
    "% Map function: emit (word, 1) pairs\n",
    "mapper = @(words) ones(size(words));  % Each word gets count of 1\n",
    "\n",
    "% Reduce function: sum counts\n",
    "reducer = @(counts) sum(counts);\n",
    "\n",
    "mr_result = mapreduce_simulation(word_count_data, mapper, reducer, 4, 2);\n",
    "\n",
    "% Compare with direct computation\n",
    "direct_result = sum(ones(size(word_count_data)));\n",
    "fprintf('   MapReduce vs direct: %.6f vs %.6f (diff: %.2e)\\n', ...\n",
    "        mr_result, direct_result, abs(mr_result - direct_result));\n",
    "```\n",
    "\n",
    "## 5. Performance Analysis and Optimization\n",
    "\n",
    "```octave\n",
    "% Performance analysis for parallel computing\n",
    "fprintf('\\n=== Performance Analysis and Optimization ===\\n');\n",
    "\n",
    "% Scalability analysis\n",
    "fprintf('1. Scalability Analysis:\\n');\n",
    "\n",
    "function results = scalability_analysis(problem_sizes, worker_counts, algorithm_func)\n",
    "    % Analyze algorithm scalability\n",
    "    % Input: problem_sizes - array of problem sizes\n",
    "    %        worker_counts - array of worker counts\n",
    "    %        algorithm_func - function to test\n",
    "    % Output: results - performance results\n",
    "    \n",
    "    results = struct();\n",
    "    results.problem_sizes = problem_sizes;\n",
    "    results.worker_counts = worker_counts;\n",
    "    results.execution_times = zeros(length(problem_sizes), length(worker_counts));\n",
    "    results.speedups = zeros(length(problem_sizes), length(worker_counts));\n",
    "    results.efficiencies = zeros(length(problem_sizes), length(worker_counts));\n",
    "    \n",
    "    fprintf('   Scalability analysis: %d problem sizes, %d worker configurations\\n', ...\n",
    "            length(problem_sizes), length(worker_counts));\n",
    "    \n",
    "    for i = 1:length(problem_sizes)\n",
    "        n = problem_sizes(i);\n",
    "        fprintf('   Problem size: %d\\n', n);\n",
    "        \n",
    "        # Generate test data\n",
    "        test_data = rand(n, 1);\n",
    "        \n",
    "        for j = 1:length(worker_counts)\n",
    "            workers = worker_counts(j);\n",
    "            \n",
    "            # Measure execution time\n",
    "            tic;\n",
    "            algorithm_func(test_data, workers);\n",
    "            exec_time = toc;\n",
    "            \n",
    "            results.execution_times(i, j) = exec_time;\n",
    "            \n",
    "            # Calculate speedup relative to single worker\n",
    "            if j == 1  % Assuming first entry is single worker\n",
    "                baseline_time = exec_time;\n",
    "                speedup = 1;\n",
    "                efficiency = 1;\n",
    "            else\n",
    "                speedup = baseline_time / exec_time;\n",
    "                efficiency = speedup / workers;\n",
    "            end\n",
    "            \n",
    "            results.speedups(i, j) = speedup;\n",
    "            results.efficiencies(i, j) = efficiency;\n",
    "            \n",
    "            fprintf('     %d workers: %.4fs (speedup: %.2fx, efficiency: %.1f%%)\\n', ...\n",
    "                    workers, exec_time, speedup, efficiency * 100);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Analysis summary\n",
    "    fprintf('   Scalability Summary:\\n');\n",
    "    avg_efficiency = mean(results.efficiencies, 1);\n",
    "    for j = 1:length(worker_counts)\n",
    "        fprintf('     %d workers: average efficiency %.1f%%\\n', ...\n",
    "                worker_counts(j), avg_efficiency(j) * 100);\n",
    "    end\n",
    "end\n",
    "\n",
    "% Test scalability with parallel sum\n",
    "test_parallel_sum = @(data, workers) parallel_reduction(data, 'sum', workers);\n",
    "\n",
    "problem_sizes = [1000, 5000, 10000];\n",
    "worker_counts = [1, 2, 4, 8];\n",
    "\n",
    "scale_results = scalability_analysis(problem_sizes, worker_counts, test_parallel_sum);\n",
    "\n",
    "% Amdahl's Law analysis\n",
    "fprintf('\\n2. Amdahl''s Law Analysis:\\n');\n",
    "\n",
    "function theoretical_speedup = amdahls_law(serial_fraction, num_processors)\n",
    "    % Calculate theoretical speedup using Amdahl's Law\n",
    "    % S = 1 / (serial_fraction + (1 - serial_fraction) / num_processors)\n",
    "    \n",
    "    theoretical_speedup = 1 ./ (serial_fraction + (1 - serial_fraction) ./ num_processors);\n",
    "end\n",
    "\n",
    "function demonstrate_amdahls_law()\n",
    "    processors = 1:16;\n",
    "    serial_fractions = [0.01, 0.05, 0.1, 0.25];\n",
    "    \n",
    "    fprintf('   Amdahl''s Law theoretical speedups:\\n');\n",
    "    fprintf('   Processors: '); fprintf('%3d ', processors); fprintf('\\n');\n",
    "    \n",
    "    for i = 1:length(serial_fractions)\n",
    "        f = serial_fractions(i);\n",
    "        speedups = amdahls_law(f, processors);\n",
    "        \n",
    "        fprintf('   Serial %.0f%%:  ', f * 100);\n",
    "        fprintf('%5.2f', speedups);\n",
    "        fprintf('\\n');\n",
    "    end\n",
    "    \n",
    "    % Maximum theoretical speedup\n",
    "    fprintf('   Maximum theoretical speedups:\\n');\n",
    "    for i = 1:length(serial_fractions)\n",
    "        f = serial_fractions(i);\n",
    "        max_speedup = 1 / f;\n",
    "        fprintf('     Serial %.0f%%: %.1fx\\n', f * 100, max_speedup);\n",
    "    end\n",
    "end\n",
    "\n",
    "demonstrate_amdahls_law();\n",
    "\n",
    "% Gustafson's Law (weak scaling)\n",
    "fprintf('\\n3. Gustafson''s Law (Weak Scaling):\\n');\n",
    "\n",
    "function scaled_speedup = gustafsons_law(serial_fraction, num_processors)\n",
    "    % Calculate speedup using Gustafson's Law (weak scaling)\n",
    "    % S = serial_fraction + num_processors * (1 - serial_fraction)\n",
    "    \n",
    "    scaled_speedup = serial_fraction + num_processors .* (1 - serial_fraction);\n",
    "end\n",
    "\n",
    "function demonstrate_gustafsons_law()\n",
    "    processors = 1:16;\n",
    "    serial_fractions = [0.01, 0.05, 0.1, 0.25];\n",
    "    \n",
    "    fprintf('   Gustafson''s Law scaled speedups:\\n');\n",
    "    fprintf('   Processors: '); fprintf('%3d ', processors); fprintf('\\n');\n",
    "    \n",
    "    for i = 1:length(serial_fractions)\n",
    "        f = serial_fractions(i);\n",
    "        speedups = gustafsons_law(f, processors);\n",
    "        \n",
    "        fprintf('   Serial %.0f%%:  ', f * 100);\n",
    "        fprintf('%5.2f', speedups);\n",
    "        fprintf('\\n');\n",
    "    end\n",
    "end\n",
    "\n",
    "demonstrate_gustafsons_law();\n",
    "\n",
    "% Cache performance analysis\n",
    "fprintf('\\n4. Cache Performance Considerations:\\n');\n",
    "\n",
    "function cache_analysis = analyze_cache_performance(data_sizes, access_patterns)\n",
    "    % Analyze cache performance for different access patterns\n",
    "    cache_analysis = struct();\n",
    "    cache_analysis.data_sizes = data_sizes;\n",
    "    cache_analysis.patterns = access_patterns;\n",
    "    cache_analysis.access_times = zeros(length(data_sizes), length(access_patterns));\n",
    "    \n",
    "    fprintf('   Cache performance analysis:\\n');\n",
    "    \n",
    "    for i = 1:length(data_sizes)\n",
    "        n = data_sizes(i);\n",
    "        data = rand(n, n);  % Square matrix\n",
    "        \n",
    "        fprintf('   Matrix size: %dx%d (%.1f MB)\\n', n, n, n*n*8/(1024^2));\n",
    "        \n",
    "        for j = 1:length(access_patterns)\n",
    "            pattern = access_patterns{j};\n",
    "            \n",
    "            tic;\n",
    "            switch pattern\n",
    "                case 'row_major'\n",
    "                    % Row-major access (cache-friendly)\n",
    "                    sum_val = 0;\n",
    "                    for row = 1:n\n",
    "                        for col = 1:n\n",
    "                            sum_val = sum_val + data(row, col);\n",
    "                        end\n",
    "                    end\n",
    "                    \n",
    "                case 'column_major'\n",
    "                    # Column-major access (cache-friendly in Octave/MATLAB)\n",
    "                    sum_val = 0;\n",
    "                    for col = 1:n\n",
    "                        for row = 1:n\n",
    "                            sum_val = sum_val + data(row, col);\n",
    "                        end\n",
    "                    end\n",
    "                    \n",
    "                case 'random'\n",
    "                    # Random access (cache-unfriendly)\n",
    "                    sum_val = 0;\n",
    "                    indices = randperm(n*n, min(1000, n*n));  % Sample random indices\n",
    "                    for k = 1:length(indices)\n",
    "                        idx = indices(k);\n",
    "                        sum_val = sum_val + data(idx);\n",
    "                    end\n",
    "                    \n",
    "                case 'blocked'\n",
    "                    # Block access (cache-optimized)\n",
    "                    sum_val = 0;\n",
    "                    block_size = 32;\n",
    "                    for block_i = 1:block_size:n\n",
    "                        for block_j = 1:block_size:n\n",
    "                            end_i = min(block_i + block_size - 1, n);\n",
    "                            end_j = min(block_j + block_size - 1, n);\n",
    "                            for row = block_i:end_i\n",
    "                                for col = block_j:end_j\n",
    "                                    sum_val = sum_val + data(row, col);\n",
    "                                end\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "            end\n",
    "            \n",
    "            access_time = toc;\n",
    "            cache_analysis.access_times(i, j) = access_time;\n",
    "            \n",
    "            fprintf('     %s: %.4f seconds\\n', pattern, access_time);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    % Relative performance analysis\n",
    "    fprintf('   Relative performance (normalized to column-major):\\n');\n",
    "    col_major_idx = find(strcmp(access_patterns, 'column_major'));\n",
    "    if ~isempty(col_major_idx)\n",
    "        for i = 1:length(data_sizes)\n",
    "            baseline = cache_analysis.access_times(i, col_major_idx);\n",
    "            fprintf('     Size %dx%d: ', data_sizes(i), data_sizes(i));\n",
    "            for j = 1:length(access_patterns)\n",
    "                relative = cache_analysis.access_times(i, j) / baseline;\n",
    "                fprintf('%s=%.2fx ', access_patterns{j}, relative);\n",
    "            end\n",
    "            fprintf('\\n');\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# Test cache performance\n",
    "test_sizes = [100, 200, 400];\n",
    "access_patterns = {'column_major', 'row_major', 'blocked', 'random'};\n",
    "\n",
    "cache_results = analyze_cache_performance(test_sizes, access_patterns);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "**Parallel Computing Mastery Completed:**\n",
    "\n",
    "This comprehensive final notebook covered all essential aspects of parallel and distributed computing:\n",
    "\n",
    "- âœ… **Parallel Fundamentals**: Parallel execution models, task scheduling, performance simulation\n",
    "- âœ… **Parallel Algorithms**: Reduction operations, parallel matrix operations, parallel sorting\n",
    "- âœ… **Load Balancing**: Dynamic load balancing, work-stealing algorithms, task distribution\n",
    "- âœ… **Distributed Computing**: Message passing, MapReduce paradigm, distributed coordination\n",
    "- âœ… **Performance Analysis**: Scalability analysis, Amdahl's and Gustafson's laws, cache optimization\n",
    "\n",
    "**Expert Parallel Computing Skills:**\n",
    "1. **Algorithm Design**: Implement efficient parallel algorithms with proper load balancing\n",
    "2. **Performance Modeling**: Apply theoretical models to predict and optimize parallel performance\n",
    "3. **Distributed Systems**: Design and coordinate distributed computational workflows\n",
    "4. **Scalability Analysis**: Evaluate and optimize applications for different scales and architectures\n",
    "5. **Memory Optimization**: Design cache-efficient algorithms for high-performance computing\n",
    "\n",
    "**Professional HPC Development:**\n",
    "- Design scalable parallel algorithms for scientific computing applications\n",
    "- Implement efficient load balancing and task distribution strategies\n",
    "- Apply performance modeling to optimize resource utilization\n",
    "- Build distributed computing systems with proper coordination mechanisms\n",
    "- Analyze and optimize memory access patterns for cache efficiency\n",
    "\n",
    "**Research and Industry Impact:**\n",
    "- **Scientific Computing**: Large-scale simulations, climate modeling, computational physics\n",
    "- **Data Analytics**: Big data processing, machine learning at scale, real-time analytics\n",
    "- **High-Performance Computing**: Supercomputing applications, grid computing, cloud computing\n",
    "- **Financial Computing**: Risk analysis, algorithmic trading, portfolio optimization\n",
    "- **Engineering**: Computational fluid dynamics, structural analysis, optimization problems\n",
    "\n",
    "**Advanced Techniques Mastered:**\n",
    "- Parallel algorithm design patterns and implementation strategies\n",
    "- Performance modeling using Amdahl's and Gustafson's laws\n",
    "- Load balancing techniques including work-stealing and dynamic scheduling\n",
    "- Distributed computing paradigms including MapReduce and message passing\n",
    "- Cache-aware algorithm design and memory optimization techniques\n",
    "\n",
    "**Next Steps for Continued Growth:**\n",
    "- Explore GPU computing and CUDA/OpenCL programming\n",
    "- Study advanced parallel programming models (OpenMP, MPI)\n",
    "- Investigate machine learning parallelization techniques\n",
    "- Apply these concepts to real-world HPC systems and clusters\n",
    "- Contribute to open-source parallel computing libraries and frameworks\n",
    "\n",
    "**ðŸŽ‰ OctaveMasterPro Journey Complete! ðŸŽ‰**\n",
    "\n",
    "You have now mastered the complete spectrum of Octave programming, from basic syntax to advanced parallel computing. Your skills span:\n",
    "\n",
    "**Foundation to Expert Pipeline:**\n",
    "- Basic programming â†’ Advanced algorithms\n",
    "- Simple plotting â†’ Publication-quality visualization  \n",
    "- Linear algebra â†’ Advanced numerical methods\n",
    "- Basic I/O â†’ Large-scale data processing\n",
    "- Sequential code â†’ Parallel and distributed computing\n",
    "\n",
    "**Professional Readiness:**\n",
    "Your OctaveMasterPro certification demonstrates expertise in scientific computing, numerical analysis, data visualization, software engineering, and high-performance computing. You're now prepared for:\n",
    "\n",
    "- **Research Positions**: Computational science, engineering research, academic positions\n",
    "- **Industry Roles**: Scientific software development, data analysis, quantitative analysis\n",
    "- **Leadership**: Technical lead for scientific computing projects and teams\n",
    "- **Innovation**: Contributing to cutting-edge computational methods and tools\n",
    "\n",
    "**Congratulations on completing OctaveMasterPro!** ðŸš€ðŸŽ¯\n",
    "\n",
    "Your journey in computational excellence begins now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
